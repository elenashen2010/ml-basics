{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with TensorFlow\n",
    "\n",
    "Classical machine learning relies on using statistics to determine relationships between features and labels, and can be very effective for creating predictive models. However, a massive growth in the availability of data coupled with advances in the computing technology required to process it has led to the emergence of new machine learning techniques that mimic the way the brain processes information in a structure called an artificial neural network.\n",
    "\n",
    "TensorFlow is a framework for creating machine learning models, including deep neural networks (DNNs). In this example, we'll use Tensorflow to create a simple neural network that classifies penguins into species based on the length and depth of their culmen (bill), their flipper length, and their body mass.\n",
    "\n",
    "> **Citation**: The penguins dataset used in the this exercise is a subset of data collected and made available by [Dr.Â Kristen\n",
    "Gorman](https://www.uaf.edu/cfos/people/faculty/detail/kristen-gorman.php)\n",
    "and the [Palmer Station, Antarctica LTER](https://pal.lternet.edu/), a\n",
    "member of the [Long Term Ecological Research\n",
    "Network](https://lternet.edu/).\n",
    "\n",
    "## Explore the dataset\n",
    "\n",
    "Before we start using TensorFlow to create a model, let's load the data we need from the Palmer Islands penguins dataset, which contains observations of three different species of penguin.\n",
    "\n",
    "> **Note**: In reality, you can solve the penguin classification problem easily using classical machine learning techniques without the need for a deep learning model; but it's a useful, easy to understand dataset with which to demonstrate the principles of neural networks in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CulmenLength</th>\n",
       "      <th>CulmenDepth</th>\n",
       "      <th>FlipperLength</th>\n",
       "      <th>BodyMass</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>41.3</td>\n",
       "      <td>21.1</td>\n",
       "      <td>19.5</td>\n",
       "      <td>44.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>48.4</td>\n",
       "      <td>14.4</td>\n",
       "      <td>20.3</td>\n",
       "      <td>46.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>42.3</td>\n",
       "      <td>21.2</td>\n",
       "      <td>19.1</td>\n",
       "      <td>41.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>45.6</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.4</td>\n",
       "      <td>35.25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>41.1</td>\n",
       "      <td>18.1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>43.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>35.9</td>\n",
       "      <td>19.2</td>\n",
       "      <td>18.9</td>\n",
       "      <td>38.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>41.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>20.1</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>50.5</td>\n",
       "      <td>15.9</td>\n",
       "      <td>22.2</td>\n",
       "      <td>55.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>43.3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>45.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>51.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>20.3</td>\n",
       "      <td>41.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CulmenLength  CulmenDepth  FlipperLength  BodyMass  Species\n",
       "61           41.3         21.1           19.5     44.00        0\n",
       "250          48.4         14.4           20.3     46.25        1\n",
       "49           42.3         21.2           19.1     41.50        0\n",
       "335          45.6         19.4           19.4     35.25        2\n",
       "91           41.1         18.1           20.5     43.00        0\n",
       "22           35.9         19.2           18.9     38.00        0\n",
       "151          41.5         18.5           20.1     40.00        0\n",
       "196          50.5         15.9           22.2     55.50        1\n",
       "260          43.3         14.0           20.8     45.75        1\n",
       "309          51.0         18.8           20.3     41.00        2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the training dataset (excluding rows with null values)\n",
    "penguins = pd.read_csv('data/penguins.csv').dropna()\n",
    "\n",
    "# Deep Learning models work best when features are on similar scales\n",
    "# In a real solution, we'd implement some custom normalization for each feature, but to keep things simple\n",
    "# we'll just rescale the FlipperLength and BodyMass so they're on a similar scale to the bill measurements\n",
    "penguins['FlipperLength'] = penguins['FlipperLength']/10\n",
    "penguins['BodyMass'] = penguins['BodyMass']/100\n",
    "\n",
    "# The dataset is too small to be useful for deep learning\n",
    "# So we'll oversample it to increase its size\n",
    "for i in range(1,3):\n",
    "    # penguins = penguins.append(penguins)\n",
    "    penguins = pd.concat([penguins, penguins])\n",
    "\n",
    "# Display a random sample of 10 observations\n",
    "sample = penguins.sample(10)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Species** column is the label our model will predict. Each label value represents a class of penguin species, encoded as 0, 1, or 2. The following code shows the actual species to which these class labels corrrespond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CulmenLength' 'CulmenDepth' 'FlipperLength' 'BodyMass' 'Species'] SpeciesName\n",
      "[ 48.2 15.6 22.1 51.0 1 ] Gentoo\n",
      "[ 51.5 18.7 18.7 32.5 2 ] Chinstrap\n",
      "[ 37.3 17.8 19.1 33.5 0 ] Adelie\n",
      "[ 45.8 14.2 21.9 47.0 1 ] Gentoo\n",
      "[ 48.1 16.4 19.9 33.25 2 ] Chinstrap\n",
      "[ 38.5 17.9 19.0 33.25 0 ] Adelie\n",
      "[ 38.1 17.6 18.7 34.25 0 ] Adelie\n",
      "[ 51.0 18.8 20.3 41.0 2 ] Chinstrap\n",
      "[ 42.5 20.7 19.7 45.0 0 ] Adelie\n",
      "[ 41.3 20.3 19.4 35.5 0 ] Adelie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evans\\AppData\\Local\\Temp\\ipykernel_46400\\3285247502.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print('[',row[0], row[1], row[2],row[3], int(row[4]), ']',penguin_classes[int(row[-1])])\n"
     ]
    }
   ],
   "source": [
    "penguin_classes = ['Adelie', 'Gentoo', 'Chinstrap']\n",
    "print(sample.columns[0:5].values, 'SpeciesName')\n",
    "for index, row in penguins.sample(10).iterrows():\n",
    "    print('[',row[0], row[1], row[2],row[3], int(row[4]), ']',penguin_classes[int(row[-1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is common in a supervised learning problem, we'll split the dataset into a set of records with which to train the model, and a smaller set with which to validate the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: 957, Test Set: 411 \n",
      "\n",
      "Sample of features and labels:\n",
      "[51.1 16.5 22.5 52.5] 1 (Gentoo)\n",
      "[50.7 19.7 20.3 40.5] 2 (Chinstrap)\n",
      "[49.5 16.2 22.9 58. ] 1 (Gentoo)\n",
      "[39.3 20.6 19.  36.5] 0 (Adelie)\n",
      "[42.5 20.7 19.7 45. ] 0 (Adelie)\n",
      "[50.  15.3 22.  55.5] 1 (Gentoo)\n",
      "[50.2  18.7  19.8  37.75] 2 (Chinstrap)\n",
      "[50.7 19.7 20.3 40.5] 2 (Chinstrap)\n",
      "[49.1  14.5  21.2  46.25] 1 (Gentoo)\n",
      "[43.2 16.6 18.7 29. ] 2 (Chinstrap)\n",
      "[38.8  17.6  19.1  32.75] 0 (Adelie)\n",
      "[37.8 17.1 18.6 33. ] 0 (Adelie)\n",
      "[45.8 14.2 21.9 47. ] 1 (Gentoo)\n",
      "[43.8 13.9 20.8 43. ] 1 (Gentoo)\n",
      "[36.  17.1 18.7 37. ] 0 (Adelie)\n",
      "[43.3 13.4 20.9 44. ] 1 (Gentoo)\n",
      "[36.  18.5 18.6 31. ] 0 (Adelie)\n",
      "[41.1  19.   18.2  34.25] 0 (Adelie)\n",
      "[33.1 16.1 17.8 29. ] 0 (Adelie)\n",
      "[40.9 13.7 21.4 46.5] 1 (Gentoo)\n",
      "[45.2 17.8 19.8 39.5] 2 (Chinstrap)\n",
      "[48.4 14.6 21.3 58.5] 1 (Gentoo)\n",
      "[43.6 13.9 21.7 49. ] 1 (Gentoo)\n",
      "[38.5  17.9  19.   33.25] 0 (Adelie)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = ['CulmenLength','CulmenDepth','FlipperLength','BodyMass']\n",
    "label = 'Species'\n",
    "   \n",
    "# Split data 70%-30% into training set and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(penguins[features].values,\n",
    "                                                    penguins[label].values,\n",
    "                                                    test_size=0.30,\n",
    "                                                    random_state=0)\n",
    "\n",
    "print ('Training Set: %d, Test Set: %d \\n' % (len(x_train), len(x_test)))\n",
    "print(\"Sample of features and labels:\")\n",
    "\n",
    "# Take a look at the first 25 training features and corresponding labels\n",
    "for n in range(0,24):\n",
    "    print(x_train[n], y_train[n], '(' + penguin_classes[y_train[n]] + ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *features* are the measurements for each penguin observation, and the *label* is a numeric value that indicates the species of penguin that the observation represents (Adelie, Gentoo, or Chinstrap).\n",
    "\n",
    "## Install and import TensorFlow libraries\n",
    "\n",
    "Since we plan to use TensorFlow to create our penguin classifier, we'll need to run the following two cells to install and import the libraries we intend to use.\n",
    "\n",
    "> **Note** *Keras* is an abstraction layer over the base TensorFlow API. In most common machine learning scenarios, you can use Keras to simplify your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\workspace\\python\\azure\\ml-basics\\.venv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\workspace\\python\\azure\\ml-basics\\.venv\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\workspace\\python\\azure\\ml-basics\\.venv\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\workspace\\python\\azure\\ml-basics\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\workspace\\python\\azure\\ml-basics\\.venv\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.17.3-cp313-cp313-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.74.0-cp313-cp313-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\workspace\\python\\azure\\ml-basics\\.venv\\lib\\site-packages (from tensorflow) (2.3.3)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Using cached h5py-3.14.0-cp313-cp313-win_amd64.whl.metadata (2.7 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.3-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\workspace\\python\\azure\\ml-basics\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\workspace\\python\\azure\\ml-basics\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\workspace\\python\\azure\\ml-basics\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\workspace\\python\\azure\\ml-basics\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in c:\\workspace\\python\\azure\\ml-basics\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Using cached rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Using cached optree-0.17.0-cp313-cp313-win_amd64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\workspace\\python\\azure\\ml-basics\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\workspace\\python\\azure\\ml-basics\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl (332.0 MB)\n",
      "   ---------------------------------------- 0.0/332.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/332.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/332.0 MB 1.3 MB/s eta 0:04:16\n",
      "   ---------------------------------------- 0.8/332.0 MB 1.4 MB/s eta 0:03:52\n",
      "   ---------------------------------------- 1.0/332.0 MB 1.5 MB/s eta 0:03:48\n",
      "   ---------------------------------------- 1.3/332.0 MB 1.4 MB/s eta 0:04:01\n",
      "   ---------------------------------------- 1.3/332.0 MB 1.4 MB/s eta 0:04:01\n",
      "   ---------------------------------------- 1.6/332.0 MB 1.1 MB/s eta 0:04:50\n",
      "   ---------------------------------------- 1.8/332.0 MB 1.2 MB/s eta 0:04:42\n",
      "   ---------------------------------------- 2.1/332.0 MB 1.1 MB/s eta 0:04:49\n",
      "   ---------------------------------------- 2.4/332.0 MB 1.2 MB/s eta 0:04:36\n",
      "   ---------------------------------------- 2.6/332.0 MB 1.2 MB/s eta 0:04:39\n",
      "   ---------------------------------------- 2.9/332.0 MB 1.2 MB/s eta 0:04:46\n",
      "   ---------------------------------------- 3.1/332.0 MB 1.2 MB/s eta 0:04:44\n",
      "   ---------------------------------------- 3.4/332.0 MB 1.2 MB/s eta 0:04:37\n",
      "   ---------------------------------------- 3.7/332.0 MB 1.2 MB/s eta 0:04:31\n",
      "   ---------------------------------------- 3.9/332.0 MB 1.2 MB/s eta 0:04:33\n",
      "    --------------------------------------- 4.2/332.0 MB 1.2 MB/s eta 0:04:34\n",
      "    --------------------------------------- 4.2/332.0 MB 1.2 MB/s eta 0:04:34\n",
      "    --------------------------------------- 4.5/332.0 MB 1.1 MB/s eta 0:04:46\n",
      "    --------------------------------------- 4.5/332.0 MB 1.1 MB/s eta 0:04:46\n",
      "    --------------------------------------- 4.7/332.0 MB 1.1 MB/s eta 0:04:52\n",
      "    --------------------------------------- 5.0/332.0 MB 1.1 MB/s eta 0:04:55\n",
      "    --------------------------------------- 5.2/332.0 MB 1.1 MB/s eta 0:05:00\n",
      "    --------------------------------------- 5.2/332.0 MB 1.1 MB/s eta 0:05:00\n",
      "    --------------------------------------- 5.5/332.0 MB 1.1 MB/s eta 0:05:02\n",
      "    --------------------------------------- 5.8/332.0 MB 1.1 MB/s eta 0:05:02\n",
      "    --------------------------------------- 6.0/332.0 MB 1.1 MB/s eta 0:05:05\n",
      "    --------------------------------------- 6.0/332.0 MB 1.1 MB/s eta 0:05:05\n",
      "    --------------------------------------- 6.0/332.0 MB 1.1 MB/s eta 0:05:05\n",
      "    --------------------------------------- 6.3/332.0 MB 1.0 MB/s eta 0:05:18\n",
      "    --------------------------------------- 6.6/332.0 MB 1.0 MB/s eta 0:05:21\n",
      "    --------------------------------------- 6.6/332.0 MB 1.0 MB/s eta 0:05:21\n",
      "    --------------------------------------- 6.8/332.0 MB 1.0 MB/s eta 0:05:22\n",
      "    --------------------------------------- 6.8/332.0 MB 1.0 MB/s eta 0:05:22\n",
      "    --------------------------------------- 7.1/332.0 MB 984.0 kB/s eta 0:05:31\n",
      "    --------------------------------------- 7.3/332.0 MB 987.1 kB/s eta 0:05:29\n",
      "    --------------------------------------- 7.3/332.0 MB 987.1 kB/s eta 0:05:29\n",
      "    --------------------------------------- 7.6/332.0 MB 975.9 kB/s eta 0:05:33\n",
      "    --------------------------------------- 7.6/332.0 MB 975.9 kB/s eta 0:05:33\n",
      "    --------------------------------------- 7.9/332.0 MB 954.4 kB/s eta 0:05:40\n",
      "    --------------------------------------- 8.1/332.0 MB 958.7 kB/s eta 0:05:38\n",
      "    --------------------------------------- 8.1/332.0 MB 958.7 kB/s eta 0:05:38\n",
      "   - -------------------------------------- 8.4/332.0 MB 955.2 kB/s eta 0:05:39\n",
      "   - -------------------------------------- 8.7/332.0 MB 951.5 kB/s eta 0:05:40\n",
      "   - -------------------------------------- 9.2/332.0 MB 978.0 kB/s eta 0:05:31\n",
      "   - -------------------------------------- 9.4/332.0 MB 995.0 kB/s eta 0:05:25\n",
      "   - -------------------------------------- 9.7/332.0 MB 1.0 MB/s eta 0:05:20\n",
      "   - -------------------------------------- 10.0/332.0 MB 1.0 MB/s eta 0:05:18\n",
      "   - -------------------------------------- 10.2/332.0 MB 1.0 MB/s eta 0:05:18\n",
      "   - -------------------------------------- 10.7/332.0 MB 1.0 MB/s eta 0:05:11\n",
      "   - -------------------------------------- 11.0/332.0 MB 1.0 MB/s eta 0:05:06\n",
      "   - -------------------------------------- 11.5/332.0 MB 1.1 MB/s eta 0:04:58\n",
      "   - -------------------------------------- 11.8/332.0 MB 1.1 MB/s eta 0:04:55\n",
      "   - -------------------------------------- 12.1/332.0 MB 1.1 MB/s eta 0:04:54\n",
      "   - -------------------------------------- 12.3/332.0 MB 1.1 MB/s eta 0:04:52\n",
      "   - -------------------------------------- 12.6/332.0 MB 1.1 MB/s eta 0:04:52\n",
      "   - -------------------------------------- 12.8/332.0 MB 1.1 MB/s eta 0:04:54\n",
      "   - -------------------------------------- 12.8/332.0 MB 1.1 MB/s eta 0:04:54\n",
      "   - -------------------------------------- 13.1/332.0 MB 1.1 MB/s eta 0:04:54\n",
      "   - -------------------------------------- 13.6/332.0 MB 1.1 MB/s eta 0:04:50\n",
      "   - -------------------------------------- 13.9/332.0 MB 1.1 MB/s eta 0:04:47\n",
      "   - -------------------------------------- 14.2/332.0 MB 1.1 MB/s eta 0:04:46\n",
      "   - -------------------------------------- 14.4/332.0 MB 1.1 MB/s eta 0:04:46\n",
      "   - -------------------------------------- 14.9/332.0 MB 1.1 MB/s eta 0:04:42\n",
      "   - -------------------------------------- 15.5/332.0 MB 1.1 MB/s eta 0:04:36\n",
      "   - -------------------------------------- 16.0/332.0 MB 1.2 MB/s eta 0:04:30\n",
      "   - -------------------------------------- 16.5/332.0 MB 1.2 MB/s eta 0:04:25\n",
      "   -- ------------------------------------- 16.8/332.0 MB 1.2 MB/s eta 0:04:24\n",
      "   -- ------------------------------------- 17.0/332.0 MB 1.2 MB/s eta 0:04:24\n",
      "   -- ------------------------------------- 17.0/332.0 MB 1.2 MB/s eta 0:04:24\n",
      "   -- ------------------------------------- 17.6/332.0 MB 1.2 MB/s eta 0:04:23\n",
      "   -- ------------------------------------- 17.8/332.0 MB 1.2 MB/s eta 0:04:22\n",
      "   -- ------------------------------------- 18.1/332.0 MB 1.2 MB/s eta 0:04:21\n",
      "   -- ------------------------------------- 18.4/332.0 MB 1.2 MB/s eta 0:04:21\n",
      "   -- ------------------------------------- 18.6/332.0 MB 1.2 MB/s eta 0:04:20\n",
      "   -- ------------------------------------- 18.9/332.0 MB 1.2 MB/s eta 0:04:20\n",
      "   -- ------------------------------------- 19.1/332.0 MB 1.2 MB/s eta 0:04:19\n",
      "   -- ------------------------------------- 19.4/332.0 MB 1.2 MB/s eta 0:04:18\n",
      "   -- ------------------------------------- 19.7/332.0 MB 1.2 MB/s eta 0:04:18\n",
      "   -- ------------------------------------- 20.2/332.0 MB 1.2 MB/s eta 0:04:16\n",
      "   -- ------------------------------------- 20.4/332.0 MB 1.2 MB/s eta 0:04:15\n",
      "   -- ------------------------------------- 20.7/332.0 MB 1.2 MB/s eta 0:04:15\n",
      "   -- ------------------------------------- 20.7/332.0 MB 1.2 MB/s eta 0:04:15\n",
      "   -- ------------------------------------- 21.0/332.0 MB 1.2 MB/s eta 0:04:16\n",
      "   -- ------------------------------------- 21.5/332.0 MB 1.2 MB/s eta 0:04:14\n",
      "   -- ------------------------------------- 21.8/332.0 MB 1.2 MB/s eta 0:04:13\n",
      "   -- ------------------------------------- 22.0/332.0 MB 1.2 MB/s eta 0:04:12\n",
      "   -- ------------------------------------- 22.5/332.0 MB 1.2 MB/s eta 0:04:10\n",
      "   -- ------------------------------------- 22.8/332.0 MB 1.2 MB/s eta 0:04:09\n",
      "   -- ------------------------------------- 23.1/332.0 MB 1.2 MB/s eta 0:04:09\n",
      "   -- ------------------------------------- 23.1/332.0 MB 1.2 MB/s eta 0:04:09\n",
      "   -- ------------------------------------- 23.3/332.0 MB 1.2 MB/s eta 0:04:09\n",
      "   -- ------------------------------------- 23.6/332.0 MB 1.2 MB/s eta 0:04:09\n",
      "   -- ------------------------------------- 23.9/332.0 MB 1.2 MB/s eta 0:04:11\n",
      "   -- ------------------------------------- 23.9/332.0 MB 1.2 MB/s eta 0:04:11\n",
      "   -- ------------------------------------- 24.1/332.0 MB 1.2 MB/s eta 0:04:12\n",
      "   -- ------------------------------------- 24.4/332.0 MB 1.2 MB/s eta 0:04:12\n",
      "   -- ------------------------------------- 24.6/332.0 MB 1.2 MB/s eta 0:04:13\n",
      "   -- ------------------------------------- 24.6/332.0 MB 1.2 MB/s eta 0:04:13\n",
      "   --- ------------------------------------ 24.9/332.0 MB 1.2 MB/s eta 0:04:13\n",
      "   --- ------------------------------------ 25.2/332.0 MB 1.2 MB/s eta 0:04:14\n",
      "   --- ------------------------------------ 25.2/332.0 MB 1.2 MB/s eta 0:04:14\n",
      "   --- ------------------------------------ 25.4/332.0 MB 1.2 MB/s eta 0:04:15\n",
      "   --- ------------------------------------ 25.7/332.0 MB 1.2 MB/s eta 0:04:15\n",
      "   --- ------------------------------------ 26.0/332.0 MB 1.2 MB/s eta 0:04:15\n",
      "   --- ------------------------------------ 26.2/332.0 MB 1.2 MB/s eta 0:04:15\n",
      "   --- ------------------------------------ 26.2/332.0 MB 1.2 MB/s eta 0:04:15\n",
      "   --- ------------------------------------ 26.5/332.0 MB 1.2 MB/s eta 0:04:16\n",
      "   --- ------------------------------------ 26.7/332.0 MB 1.2 MB/s eta 0:04:17\n",
      "   --- ------------------------------------ 26.7/332.0 MB 1.2 MB/s eta 0:04:17\n",
      "   --- ------------------------------------ 27.3/332.0 MB 1.2 MB/s eta 0:04:17\n",
      "   --- ------------------------------------ 27.5/332.0 MB 1.2 MB/s eta 0:04:16\n",
      "   --- ------------------------------------ 27.8/332.0 MB 1.2 MB/s eta 0:04:16\n",
      "   --- ------------------------------------ 27.8/332.0 MB 1.2 MB/s eta 0:04:16\n",
      "   --- ------------------------------------ 28.0/332.0 MB 1.2 MB/s eta 0:04:16\n",
      "   --- ------------------------------------ 28.3/332.0 MB 1.2 MB/s eta 0:04:16\n",
      "   --- ------------------------------------ 28.6/332.0 MB 1.2 MB/s eta 0:04:16\n",
      "   --- ------------------------------------ 28.8/332.0 MB 1.2 MB/s eta 0:04:16\n",
      "   --- ------------------------------------ 29.1/332.0 MB 1.2 MB/s eta 0:04:15\n",
      "   --- ------------------------------------ 29.6/332.0 MB 1.2 MB/s eta 0:04:13\n",
      "   --- ------------------------------------ 29.9/332.0 MB 1.2 MB/s eta 0:04:12\n",
      "   --- ------------------------------------ 30.4/332.0 MB 1.2 MB/s eta 0:04:10\n",
      "   --- ------------------------------------ 30.4/332.0 MB 1.2 MB/s eta 0:04:10\n",
      "   --- ------------------------------------ 30.9/332.0 MB 1.2 MB/s eta 0:04:09\n",
      "   --- ------------------------------------ 31.5/332.0 MB 1.2 MB/s eta 0:04:07\n",
      "   --- ------------------------------------ 32.0/332.0 MB 1.2 MB/s eta 0:04:04\n",
      "   --- ------------------------------------ 32.0/332.0 MB 1.2 MB/s eta 0:04:04\n",
      "   --- ------------------------------------ 32.2/332.0 MB 1.2 MB/s eta 0:04:05\n",
      "   --- ------------------------------------ 32.5/332.0 MB 1.2 MB/s eta 0:04:06\n",
      "   --- ------------------------------------ 32.5/332.0 MB 1.2 MB/s eta 0:04:06\n",
      "   --- ------------------------------------ 32.8/332.0 MB 1.2 MB/s eta 0:04:08\n",
      "   --- ------------------------------------ 32.8/332.0 MB 1.2 MB/s eta 0:04:08\n",
      "   --- ------------------------------------ 33.0/332.0 MB 1.2 MB/s eta 0:04:09\n",
      "   ---- ----------------------------------- 33.3/332.0 MB 1.2 MB/s eta 0:04:08\n",
      "   ---- ----------------------------------- 33.8/332.0 MB 1.2 MB/s eta 0:04:06\n",
      "   ---- ----------------------------------- 34.1/332.0 MB 1.2 MB/s eta 0:04:06\n",
      "   ---- ----------------------------------- 34.6/332.0 MB 1.2 MB/s eta 0:04:03\n",
      "   ---- ----------------------------------- 35.1/332.0 MB 1.2 MB/s eta 0:04:01\n",
      "   ---- ----------------------------------- 35.7/332.0 MB 1.2 MB/s eta 0:03:59\n",
      "   ---- ----------------------------------- 36.4/332.0 MB 1.3 MB/s eta 0:03:55\n",
      "   ---- ----------------------------------- 36.7/332.0 MB 1.3 MB/s eta 0:03:55\n",
      "   ---- ----------------------------------- 36.7/332.0 MB 1.3 MB/s eta 0:03:55\n",
      "   ---- ----------------------------------- 37.0/332.0 MB 1.3 MB/s eta 0:03:55\n",
      "   ---- ----------------------------------- 37.2/332.0 MB 1.3 MB/s eta 0:03:56\n",
      "   ---- ----------------------------------- 37.2/332.0 MB 1.3 MB/s eta 0:03:56\n",
      "   ---- ----------------------------------- 37.5/332.0 MB 1.2 MB/s eta 0:03:57\n",
      "   ---- ----------------------------------- 37.7/332.0 MB 1.2 MB/s eta 0:03:56\n",
      "   ---- ----------------------------------- 38.0/332.0 MB 1.2 MB/s eta 0:03:56\n",
      "   ---- ----------------------------------- 38.3/332.0 MB 1.2 MB/s eta 0:03:56\n",
      "   ---- ----------------------------------- 38.8/332.0 MB 1.3 MB/s eta 0:03:55\n",
      "   ---- ----------------------------------- 39.1/332.0 MB 1.3 MB/s eta 0:03:53\n",
      "   ---- ----------------------------------- 39.3/332.0 MB 1.3 MB/s eta 0:03:53\n",
      "   ---- ----------------------------------- 39.6/332.0 MB 1.3 MB/s eta 0:03:52\n",
      "   ---- ----------------------------------- 39.8/332.0 MB 1.3 MB/s eta 0:03:51\n",
      "   ---- ----------------------------------- 40.4/332.0 MB 1.3 MB/s eta 0:03:51\n",
      "   ---- ----------------------------------- 40.6/332.0 MB 1.3 MB/s eta 0:03:50\n",
      "   ---- ----------------------------------- 40.9/332.0 MB 1.3 MB/s eta 0:03:49\n",
      "   ---- ----------------------------------- 41.2/332.0 MB 1.3 MB/s eta 0:03:49\n",
      "   ---- ----------------------------------- 41.4/332.0 MB 1.3 MB/s eta 0:03:49\n",
      "   ----- ---------------------------------- 41.7/332.0 MB 1.3 MB/s eta 0:03:49\n",
      "   ----- ---------------------------------- 42.2/332.0 MB 1.3 MB/s eta 0:03:48\n",
      "   ----- ---------------------------------- 42.7/332.0 MB 1.3 MB/s eta 0:03:46\n",
      "   ----- ---------------------------------- 43.3/332.0 MB 1.3 MB/s eta 0:03:42\n",
      "   ----- ---------------------------------- 43.8/332.0 MB 1.3 MB/s eta 0:03:40\n",
      "   ----- ---------------------------------- 44.0/332.0 MB 1.3 MB/s eta 0:03:39\n",
      "   ----- ---------------------------------- 44.3/332.0 MB 1.3 MB/s eta 0:03:38\n",
      "   ----- ---------------------------------- 44.6/332.0 MB 1.3 MB/s eta 0:03:38\n",
      "   ----- ---------------------------------- 45.1/332.0 MB 1.3 MB/s eta 0:03:36\n",
      "   ----- ---------------------------------- 45.4/332.0 MB 1.3 MB/s eta 0:03:35\n",
      "   ----- ---------------------------------- 45.6/332.0 MB 1.3 MB/s eta 0:03:35\n",
      "   ----- ---------------------------------- 45.9/332.0 MB 1.3 MB/s eta 0:03:34\n",
      "   ----- ---------------------------------- 46.1/332.0 MB 1.3 MB/s eta 0:03:33\n",
      "   ----- ---------------------------------- 46.7/332.0 MB 1.4 MB/s eta 0:03:30\n",
      "   ----- ---------------------------------- 46.9/332.0 MB 1.4 MB/s eta 0:03:29\n",
      "   ----- ---------------------------------- 47.4/332.0 MB 1.4 MB/s eta 0:03:28\n",
      "   ----- ---------------------------------- 47.7/332.0 MB 1.4 MB/s eta 0:03:26\n",
      "   ----- ---------------------------------- 48.0/332.0 MB 1.4 MB/s eta 0:03:26\n",
      "   ----- ---------------------------------- 48.5/332.0 MB 1.4 MB/s eta 0:03:23\n",
      "   ----- ---------------------------------- 48.8/332.0 MB 1.4 MB/s eta 0:03:22\n",
      "   ----- ---------------------------------- 49.3/332.0 MB 1.4 MB/s eta 0:03:21\n",
      "   ------ --------------------------------- 50.1/332.0 MB 1.4 MB/s eta 0:03:18\n",
      "   ------ --------------------------------- 50.9/332.0 MB 1.5 MB/s eta 0:03:14\n",
      "   ------ --------------------------------- 51.1/332.0 MB 1.5 MB/s eta 0:03:13\n",
      "   ------ --------------------------------- 51.6/332.0 MB 1.5 MB/s eta 0:03:11\n",
      "   ------ --------------------------------- 51.6/332.0 MB 1.5 MB/s eta 0:03:11\n",
      "   ------ --------------------------------- 51.9/332.0 MB 1.5 MB/s eta 0:03:11\n",
      "   ------ --------------------------------- 51.9/332.0 MB 1.5 MB/s eta 0:03:11\n",
      "   ------ --------------------------------- 52.2/332.0 MB 1.5 MB/s eta 0:03:12\n",
      "   ------ --------------------------------- 52.7/332.0 MB 1.5 MB/s eta 0:03:11\n",
      "   ------ --------------------------------- 53.2/332.0 MB 1.5 MB/s eta 0:03:10\n",
      "   ------ --------------------------------- 53.7/332.0 MB 1.5 MB/s eta 0:03:09\n",
      "   ------ --------------------------------- 54.0/332.0 MB 1.5 MB/s eta 0:03:09\n",
      "   ------ --------------------------------- 54.3/332.0 MB 1.5 MB/s eta 0:03:08\n",
      "   ------ --------------------------------- 54.8/332.0 MB 1.5 MB/s eta 0:03:07\n",
      "   ------ --------------------------------- 55.3/332.0 MB 1.5 MB/s eta 0:03:06\n",
      "   ------ --------------------------------- 55.8/332.0 MB 1.5 MB/s eta 0:03:05\n",
      "   ------ --------------------------------- 56.6/332.0 MB 1.5 MB/s eta 0:03:03\n",
      "   ------ --------------------------------- 57.4/332.0 MB 1.5 MB/s eta 0:03:01\n",
      "   ------- -------------------------------- 58.2/332.0 MB 1.5 MB/s eta 0:02:58\n",
      "   ------- -------------------------------- 58.7/332.0 MB 1.5 MB/s eta 0:02:57\n",
      "   ------- -------------------------------- 59.0/332.0 MB 1.5 MB/s eta 0:02:57\n",
      "   ------- -------------------------------- 59.2/332.0 MB 1.6 MB/s eta 0:02:56\n",
      "   ------- -------------------------------- 59.5/332.0 MB 1.6 MB/s eta 0:02:56\n",
      "   ------- -------------------------------- 59.8/332.0 MB 1.6 MB/s eta 0:02:55\n",
      "   ------- -------------------------------- 60.6/332.0 MB 1.6 MB/s eta 0:02:54\n",
      "   ------- -------------------------------- 61.1/332.0 MB 1.6 MB/s eta 0:02:53\n",
      "   ------- -------------------------------- 61.3/332.0 MB 1.6 MB/s eta 0:02:52\n",
      "   ------- -------------------------------- 61.6/332.0 MB 1.6 MB/s eta 0:02:51\n",
      "   ------- -------------------------------- 61.9/332.0 MB 1.6 MB/s eta 0:02:52\n",
      "   ------- -------------------------------- 62.1/332.0 MB 1.6 MB/s eta 0:02:53\n",
      "   ------- -------------------------------- 62.4/332.0 MB 1.6 MB/s eta 0:02:53\n",
      "   ------- -------------------------------- 62.7/332.0 MB 1.6 MB/s eta 0:02:54\n",
      "   ------- -------------------------------- 62.9/332.0 MB 1.5 MB/s eta 0:02:54\n",
      "   ------- -------------------------------- 62.9/332.0 MB 1.5 MB/s eta 0:02:54\n",
      "   ------- -------------------------------- 63.2/332.0 MB 1.5 MB/s eta 0:02:55\n",
      "   ------- -------------------------------- 63.4/332.0 MB 1.5 MB/s eta 0:02:54\n",
      "   ------- -------------------------------- 63.7/332.0 MB 1.5 MB/s eta 0:02:55\n",
      "   ------- -------------------------------- 64.0/332.0 MB 1.5 MB/s eta 0:02:55\n",
      "   ------- -------------------------------- 64.0/332.0 MB 1.5 MB/s eta 0:02:55\n",
      "   ------- -------------------------------- 64.5/332.0 MB 1.5 MB/s eta 0:02:55\n",
      "   ------- -------------------------------- 64.7/332.0 MB 1.5 MB/s eta 0:02:55\n",
      "   ------- -------------------------------- 65.0/332.0 MB 1.5 MB/s eta 0:02:55\n",
      "   ------- -------------------------------- 65.3/332.0 MB 1.5 MB/s eta 0:02:55\n",
      "   ------- -------------------------------- 65.3/332.0 MB 1.5 MB/s eta 0:02:55\n",
      "   ------- -------------------------------- 65.5/332.0 MB 1.5 MB/s eta 0:02:55\n",
      "   ------- -------------------------------- 65.5/332.0 MB 1.5 MB/s eta 0:02:55\n",
      "   ------- -------------------------------- 65.8/332.0 MB 1.5 MB/s eta 0:02:57\n",
      "   ------- -------------------------------- 65.8/332.0 MB 1.5 MB/s eta 0:02:57\n",
      "   ------- -------------------------------- 66.1/332.0 MB 1.5 MB/s eta 0:02:56\n",
      "   ------- -------------------------------- 66.3/332.0 MB 1.5 MB/s eta 0:02:57\n",
      "   -------- ------------------------------- 66.6/332.0 MB 1.5 MB/s eta 0:02:57\n",
      "   -------- ------------------------------- 67.1/332.0 MB 1.5 MB/s eta 0:02:56\n",
      "   -------- ------------------------------- 67.4/332.0 MB 1.5 MB/s eta 0:02:56\n",
      "   -------- ------------------------------- 67.6/332.0 MB 1.5 MB/s eta 0:02:56\n",
      "   -------- ------------------------------- 67.9/332.0 MB 1.5 MB/s eta 0:02:56\n",
      "   -------- ------------------------------- 68.2/332.0 MB 1.5 MB/s eta 0:02:55\n",
      "   -------- ------------------------------- 68.7/332.0 MB 1.5 MB/s eta 0:02:54\n",
      "   -------- ------------------------------- 68.9/332.0 MB 1.5 MB/s eta 0:02:54\n",
      "   -------- ------------------------------- 69.2/332.0 MB 1.5 MB/s eta 0:02:54\n",
      "   -------- ------------------------------- 69.2/332.0 MB 1.5 MB/s eta 0:02:54\n",
      "   -------- ------------------------------- 69.5/332.0 MB 1.5 MB/s eta 0:02:53\n",
      "   -------- ------------------------------- 70.0/332.0 MB 1.5 MB/s eta 0:02:52\n",
      "   -------- ------------------------------- 70.5/332.0 MB 1.5 MB/s eta 0:02:50\n",
      "   -------- ------------------------------- 70.8/332.0 MB 1.5 MB/s eta 0:02:50\n",
      "   -------- ------------------------------- 71.0/332.0 MB 1.5 MB/s eta 0:02:50\n",
      "   -------- ------------------------------- 71.3/332.0 MB 1.5 MB/s eta 0:02:49\n",
      "   -------- ------------------------------- 71.6/332.0 MB 1.5 MB/s eta 0:02:49\n",
      "   -------- ------------------------------- 71.8/332.0 MB 1.6 MB/s eta 0:02:48\n",
      "   -------- ------------------------------- 72.1/332.0 MB 1.6 MB/s eta 0:02:48\n",
      "   -------- ------------------------------- 72.4/332.0 MB 1.6 MB/s eta 0:02:47\n",
      "   -------- ------------------------------- 72.6/332.0 MB 1.6 MB/s eta 0:02:47\n",
      "   -------- ------------------------------- 72.9/332.0 MB 1.6 MB/s eta 0:02:47\n",
      "   -------- ------------------------------- 73.4/332.0 MB 1.6 MB/s eta 0:02:46\n",
      "   -------- ------------------------------- 73.7/332.0 MB 1.6 MB/s eta 0:02:44\n",
      "   -------- ------------------------------- 73.9/332.0 MB 1.6 MB/s eta 0:02:44\n",
      "   -------- ------------------------------- 74.2/332.0 MB 1.6 MB/s eta 0:02:44\n",
      "   -------- ------------------------------- 74.4/332.0 MB 1.6 MB/s eta 0:02:44\n",
      "   -------- ------------------------------- 74.4/332.0 MB 1.6 MB/s eta 0:02:44\n",
      "   --------- ------------------------------ 74.7/332.0 MB 1.6 MB/s eta 0:02:44\n",
      "   --------- ------------------------------ 75.2/332.0 MB 1.6 MB/s eta 0:02:44\n",
      "   --------- ------------------------------ 75.2/332.0 MB 1.6 MB/s eta 0:02:44\n",
      "   --------- ------------------------------ 75.8/332.0 MB 1.6 MB/s eta 0:02:43\n",
      "   --------- ------------------------------ 76.0/332.0 MB 1.6 MB/s eta 0:02:42\n",
      "   --------- ------------------------------ 76.3/332.0 MB 1.6 MB/s eta 0:02:43\n",
      "   --------- ------------------------------ 76.5/332.0 MB 1.6 MB/s eta 0:02:42\n",
      "   --------- ------------------------------ 77.1/332.0 MB 1.6 MB/s eta 0:02:42\n",
      "   --------- ------------------------------ 77.3/332.0 MB 1.6 MB/s eta 0:02:42\n",
      "   --------- ------------------------------ 77.6/332.0 MB 1.6 MB/s eta 0:02:42\n",
      "   --------- ------------------------------ 77.9/332.0 MB 1.6 MB/s eta 0:02:41\n",
      "   --------- ------------------------------ 78.1/332.0 MB 1.6 MB/s eta 0:02:41\n",
      "   --------- ------------------------------ 78.6/332.0 MB 1.6 MB/s eta 0:02:42\n",
      "   --------- ------------------------------ 78.9/332.0 MB 1.6 MB/s eta 0:02:42\n",
      "   --------- ------------------------------ 79.4/332.0 MB 1.6 MB/s eta 0:02:41\n",
      "   --------- ------------------------------ 79.7/332.0 MB 1.6 MB/s eta 0:02:39\n",
      "   --------- ------------------------------ 80.0/332.0 MB 1.6 MB/s eta 0:02:39\n",
      "   --------- ------------------------------ 80.5/332.0 MB 1.6 MB/s eta 0:02:37\n",
      "   --------- ------------------------------ 81.0/332.0 MB 1.6 MB/s eta 0:02:36\n",
      "   --------- ------------------------------ 81.3/332.0 MB 1.6 MB/s eta 0:02:35\n",
      "   --------- ------------------------------ 81.8/332.0 MB 1.6 MB/s eta 0:02:34\n",
      "   --------- ------------------------------ 82.3/332.0 MB 1.6 MB/s eta 0:02:34\n",
      "   --------- ------------------------------ 82.6/332.0 MB 1.6 MB/s eta 0:02:34\n",
      "   --------- ------------------------------ 82.8/332.0 MB 1.6 MB/s eta 0:02:34\n",
      "   ---------- ----------------------------- 83.1/332.0 MB 1.6 MB/s eta 0:02:34\n",
      "   ---------- ----------------------------- 83.4/332.0 MB 1.6 MB/s eta 0:02:34\n",
      "   ---------- ----------------------------- 83.6/332.0 MB 1.6 MB/s eta 0:02:35\n",
      "   ---------- ----------------------------- 83.6/332.0 MB 1.6 MB/s eta 0:02:35\n",
      "   ---------- ----------------------------- 84.1/332.0 MB 1.6 MB/s eta 0:02:36\n",
      "   ---------- ----------------------------- 84.4/332.0 MB 1.6 MB/s eta 0:02:36\n",
      "   ---------- ----------------------------- 84.7/332.0 MB 1.6 MB/s eta 0:02:35\n",
      "   ---------- ----------------------------- 84.9/332.0 MB 1.6 MB/s eta 0:02:35\n",
      "   ---------- ----------------------------- 84.9/332.0 MB 1.6 MB/s eta 0:02:35\n",
      "   ---------- ----------------------------- 85.2/332.0 MB 1.6 MB/s eta 0:02:35\n",
      "   ---------- ----------------------------- 85.7/332.0 MB 1.6 MB/s eta 0:02:35\n",
      "   ---------- ----------------------------- 86.0/332.0 MB 1.6 MB/s eta 0:02:34\n",
      "   ---------- ----------------------------- 86.5/332.0 MB 1.6 MB/s eta 0:02:34\n",
      "   ---------- ----------------------------- 86.8/332.0 MB 1.6 MB/s eta 0:02:34\n",
      "   ---------- ----------------------------- 87.0/332.0 MB 1.6 MB/s eta 0:02:34\n",
      "   ---------- ----------------------------- 87.3/332.0 MB 1.6 MB/s eta 0:02:34\n",
      "   ---------- ----------------------------- 87.6/332.0 MB 1.6 MB/s eta 0:02:33\n",
      "   ---------- ----------------------------- 88.1/332.0 MB 1.6 MB/s eta 0:02:32\n",
      "   ---------- ----------------------------- 88.3/332.0 MB 1.6 MB/s eta 0:02:32\n",
      "   ---------- ----------------------------- 88.6/332.0 MB 1.6 MB/s eta 0:02:32\n",
      "   ---------- ----------------------------- 88.9/332.0 MB 1.6 MB/s eta 0:02:32\n",
      "   ---------- ----------------------------- 89.1/332.0 MB 1.6 MB/s eta 0:02:32\n",
      "   ---------- ----------------------------- 89.4/332.0 MB 1.6 MB/s eta 0:02:32\n",
      "   ---------- ----------------------------- 89.7/332.0 MB 1.6 MB/s eta 0:02:32\n",
      "   ---------- ----------------------------- 90.2/332.0 MB 1.6 MB/s eta 0:02:31\n",
      "   ---------- ----------------------------- 90.7/332.0 MB 1.6 MB/s eta 0:02:30\n",
      "   ---------- ----------------------------- 91.0/332.0 MB 1.6 MB/s eta 0:02:31\n",
      "   ---------- ----------------------------- 91.2/332.0 MB 1.6 MB/s eta 0:02:32\n",
      "   ----------- ---------------------------- 91.8/332.0 MB 1.6 MB/s eta 0:02:32\n",
      "   ----------- ---------------------------- 92.0/332.0 MB 1.6 MB/s eta 0:02:31\n",
      "   ----------- ---------------------------- 92.3/332.0 MB 1.6 MB/s eta 0:02:32\n",
      "   ----------- ---------------------------- 92.3/332.0 MB 1.6 MB/s eta 0:02:32\n",
      "   ----------- ---------------------------- 92.5/332.0 MB 1.6 MB/s eta 0:02:32\n",
      "   ----------- ---------------------------- 92.8/332.0 MB 1.6 MB/s eta 0:02:32\n",
      "   ----------- ---------------------------- 93.3/332.0 MB 1.6 MB/s eta 0:02:31\n",
      "   ----------- ---------------------------- 93.8/332.0 MB 1.6 MB/s eta 0:02:31\n",
      "   ----------- ---------------------------- 94.4/332.0 MB 1.6 MB/s eta 0:02:30\n",
      "   ----------- ---------------------------- 95.2/332.0 MB 1.6 MB/s eta 0:02:28\n",
      "   ----------- ---------------------------- 95.4/332.0 MB 1.6 MB/s eta 0:02:28\n",
      "   ----------- ---------------------------- 95.9/332.0 MB 1.6 MB/s eta 0:02:27\n",
      "   ----------- ---------------------------- 96.2/332.0 MB 1.6 MB/s eta 0:02:27\n",
      "   ----------- ---------------------------- 96.7/332.0 MB 1.6 MB/s eta 0:02:27\n",
      "   ----------- ---------------------------- 97.0/332.0 MB 1.6 MB/s eta 0:02:27\n",
      "   ----------- ---------------------------- 97.3/332.0 MB 1.6 MB/s eta 0:02:28\n",
      "   ----------- ---------------------------- 97.3/332.0 MB 1.6 MB/s eta 0:02:28\n",
      "   ----------- ---------------------------- 97.5/332.0 MB 1.6 MB/s eta 0:02:30\n",
      "   ----------- ---------------------------- 97.8/332.0 MB 1.6 MB/s eta 0:02:31\n",
      "   ----------- ---------------------------- 98.0/332.0 MB 1.6 MB/s eta 0:02:31\n",
      "   ----------- ---------------------------- 98.3/332.0 MB 1.6 MB/s eta 0:02:31\n",
      "   ----------- ---------------------------- 98.8/332.0 MB 1.6 MB/s eta 0:02:28\n",
      "   ----------- ---------------------------- 99.4/332.0 MB 1.6 MB/s eta 0:02:27\n",
      "   ------------ --------------------------- 99.6/332.0 MB 1.6 MB/s eta 0:02:27\n",
      "   ------------ --------------------------- 99.9/332.0 MB 1.6 MB/s eta 0:02:27\n",
      "   ------------ --------------------------- 100.1/332.0 MB 1.6 MB/s eta 0:02:28\n",
      "   ------------ --------------------------- 100.7/332.0 MB 1.6 MB/s eta 0:02:28\n",
      "   ------------ --------------------------- 100.9/332.0 MB 1.6 MB/s eta 0:02:28\n",
      "   ------------ --------------------------- 101.4/332.0 MB 1.6 MB/s eta 0:02:27\n",
      "   ------------ --------------------------- 101.7/332.0 MB 1.6 MB/s eta 0:02:27\n",
      "   ------------ --------------------------- 102.2/332.0 MB 1.6 MB/s eta 0:02:27\n",
      "   ------------ --------------------------- 102.8/332.0 MB 1.6 MB/s eta 0:02:27\n",
      "   ------------ --------------------------- 103.3/332.0 MB 1.6 MB/s eta 0:02:27\n",
      "   ------------ --------------------------- 103.5/332.0 MB 1.5 MB/s eta 0:02:29\n",
      "   ------------ --------------------------- 104.1/332.0 MB 1.5 MB/s eta 0:02:29\n",
      "   ------------ --------------------------- 104.3/332.0 MB 1.5 MB/s eta 0:02:30\n",
      "   ------------ --------------------------- 104.9/332.0 MB 1.5 MB/s eta 0:02:29\n",
      "   ------------ --------------------------- 105.1/332.0 MB 1.5 MB/s eta 0:02:28\n",
      "   ------------ --------------------------- 105.4/332.0 MB 1.5 MB/s eta 0:02:28\n",
      "   ------------ --------------------------- 105.6/332.0 MB 1.5 MB/s eta 0:02:28\n",
      "   ------------ --------------------------- 105.9/332.0 MB 1.5 MB/s eta 0:02:29\n",
      "   ------------ --------------------------- 106.2/332.0 MB 1.5 MB/s eta 0:02:30\n",
      "   ------------ --------------------------- 106.4/332.0 MB 1.5 MB/s eta 0:02:30\n",
      "   ------------ --------------------------- 106.7/332.0 MB 1.5 MB/s eta 0:02:30\n",
      "   ------------ --------------------------- 107.0/332.0 MB 1.5 MB/s eta 0:02:30\n",
      "   ------------ --------------------------- 107.5/332.0 MB 1.5 MB/s eta 0:02:29\n",
      "   ------------ --------------------------- 107.7/332.0 MB 1.5 MB/s eta 0:02:29\n",
      "   ------------- -------------------------- 108.0/332.0 MB 1.5 MB/s eta 0:02:29\n",
      "   ------------- -------------------------- 108.3/332.0 MB 1.5 MB/s eta 0:02:28\n",
      "   ------------- -------------------------- 108.5/332.0 MB 1.5 MB/s eta 0:02:28\n",
      "   ------------- -------------------------- 108.8/332.0 MB 1.5 MB/s eta 0:02:27\n",
      "   ------------- -------------------------- 109.3/332.0 MB 1.5 MB/s eta 0:02:26\n",
      "   ------------- -------------------------- 109.8/332.0 MB 1.5 MB/s eta 0:02:25\n",
      "   ------------- -------------------------- 110.1/332.0 MB 1.5 MB/s eta 0:02:25\n",
      "   ------------- -------------------------- 110.9/332.0 MB 1.6 MB/s eta 0:02:23\n",
      "   ------------- -------------------------- 111.4/332.0 MB 1.6 MB/s eta 0:02:21\n",
      "   ------------- -------------------------- 112.2/332.0 MB 1.6 MB/s eta 0:02:19\n",
      "   ------------- -------------------------- 112.5/332.0 MB 1.6 MB/s eta 0:02:19\n",
      "   ------------- -------------------------- 113.0/332.0 MB 1.6 MB/s eta 0:02:18\n",
      "   ------------- -------------------------- 113.5/332.0 MB 1.6 MB/s eta 0:02:16\n",
      "   ------------- -------------------------- 114.3/332.0 MB 1.6 MB/s eta 0:02:13\n",
      "   ------------- -------------------------- 115.3/332.0 MB 1.7 MB/s eta 0:02:11\n",
      "   ------------- -------------------------- 116.1/332.0 MB 1.7 MB/s eta 0:02:09\n",
      "   -------------- ------------------------- 116.9/332.0 MB 1.7 MB/s eta 0:02:07\n",
      "   -------------- ------------------------- 117.7/332.0 MB 1.7 MB/s eta 0:02:05\n",
      "   -------------- ------------------------- 118.2/332.0 MB 1.7 MB/s eta 0:02:04\n",
      "   -------------- ------------------------- 119.3/332.0 MB 1.8 MB/s eta 0:02:02\n",
      "   -------------- ------------------------- 120.3/332.0 MB 1.8 MB/s eta 0:02:00\n",
      "   -------------- ------------------------- 121.6/332.0 MB 1.8 MB/s eta 0:01:57\n",
      "   -------------- ------------------------- 122.7/332.0 MB 1.8 MB/s eta 0:01:55\n",
      "   -------------- ------------------------- 123.5/332.0 MB 1.9 MB/s eta 0:01:53\n",
      "   -------------- ------------------------- 123.7/332.0 MB 1.9 MB/s eta 0:01:53\n",
      "   -------------- ------------------------- 124.3/332.0 MB 1.9 MB/s eta 0:01:52\n",
      "   --------------- ------------------------ 124.8/332.0 MB 1.9 MB/s eta 0:01:52\n",
      "   --------------- ------------------------ 125.6/332.0 MB 1.9 MB/s eta 0:01:50\n",
      "   --------------- ------------------------ 125.8/332.0 MB 1.9 MB/s eta 0:01:49\n",
      "   --------------- ------------------------ 126.6/332.0 MB 1.9 MB/s eta 0:01:49\n",
      "   --------------- ------------------------ 126.9/332.0 MB 1.9 MB/s eta 0:01:49\n",
      "   --------------- ------------------------ 127.7/332.0 MB 1.9 MB/s eta 0:01:48\n",
      "   --------------- ------------------------ 128.2/332.0 MB 1.9 MB/s eta 0:01:47\n",
      "   --------------- ------------------------ 129.0/332.0 MB 1.9 MB/s eta 0:01:45\n",
      "   --------------- ------------------------ 129.2/332.0 MB 1.9 MB/s eta 0:01:45\n",
      "   --------------- ------------------------ 129.8/332.0 MB 1.9 MB/s eta 0:01:45\n",
      "   --------------- ------------------------ 130.0/332.0 MB 1.9 MB/s eta 0:01:44\n",
      "   --------------- ------------------------ 130.3/332.0 MB 1.9 MB/s eta 0:01:44\n",
      "   --------------- ------------------------ 131.1/332.0 MB 2.0 MB/s eta 0:01:43\n",
      "   --------------- ------------------------ 131.3/332.0 MB 2.0 MB/s eta 0:01:43\n",
      "   --------------- ------------------------ 132.1/332.0 MB 2.0 MB/s eta 0:01:42\n",
      "   ---------------- ----------------------- 132.9/332.0 MB 2.0 MB/s eta 0:01:41\n",
      "   ---------------- ----------------------- 133.7/332.0 MB 2.0 MB/s eta 0:01:40\n",
      "   ---------------- ----------------------- 134.7/332.0 MB 2.0 MB/s eta 0:01:38\n",
      "   ---------------- ----------------------- 135.5/332.0 MB 2.1 MB/s eta 0:01:36\n",
      "   ---------------- ----------------------- 136.3/332.0 MB 2.1 MB/s eta 0:01:35\n",
      "   ---------------- ----------------------- 137.1/332.0 MB 2.1 MB/s eta 0:01:34\n",
      "   ---------------- ----------------------- 137.4/332.0 MB 2.1 MB/s eta 0:01:34\n",
      "   ---------------- ----------------------- 137.9/332.0 MB 2.1 MB/s eta 0:01:33\n",
      "   ---------------- ----------------------- 138.7/332.0 MB 2.1 MB/s eta 0:01:32\n",
      "   ---------------- ----------------------- 139.5/332.0 MB 2.1 MB/s eta 0:01:31\n",
      "   ---------------- ----------------------- 140.5/332.0 MB 2.2 MB/s eta 0:01:29\n",
      "   ----------------- ---------------------- 141.6/332.0 MB 2.2 MB/s eta 0:01:28\n",
      "   ----------------- ---------------------- 142.6/332.0 MB 2.2 MB/s eta 0:01:27\n",
      "   ----------------- ---------------------- 143.4/332.0 MB 2.2 MB/s eta 0:01:26\n",
      "   ----------------- ---------------------- 143.9/332.0 MB 2.2 MB/s eta 0:01:25\n",
      "   ----------------- ---------------------- 144.4/332.0 MB 2.2 MB/s eta 0:01:25\n",
      "   ----------------- ---------------------- 145.0/332.0 MB 2.2 MB/s eta 0:01:24\n",
      "   ----------------- ---------------------- 145.5/332.0 MB 2.2 MB/s eta 0:01:24\n",
      "   ----------------- ---------------------- 145.8/332.0 MB 2.2 MB/s eta 0:01:23\n",
      "   ----------------- ---------------------- 146.3/332.0 MB 2.2 MB/s eta 0:01:23\n",
      "   ----------------- ---------------------- 147.1/332.0 MB 2.3 MB/s eta 0:01:23\n",
      "   ----------------- ---------------------- 147.8/332.0 MB 2.3 MB/s eta 0:01:22\n",
      "   ----------------- ---------------------- 148.4/332.0 MB 2.3 MB/s eta 0:01:21\n",
      "   ----------------- ---------------------- 148.9/332.0 MB 2.3 MB/s eta 0:01:21\n",
      "   ------------------ --------------------- 149.4/332.0 MB 2.3 MB/s eta 0:01:20\n",
      "   ------------------ --------------------- 150.2/332.0 MB 2.3 MB/s eta 0:01:20\n",
      "   ------------------ --------------------- 151.0/332.0 MB 2.3 MB/s eta 0:01:19\n",
      "   ------------------ --------------------- 151.5/332.0 MB 2.3 MB/s eta 0:01:18\n",
      "   ------------------ --------------------- 152.3/332.0 MB 2.3 MB/s eta 0:01:18\n",
      "   ------------------ --------------------- 152.8/332.0 MB 2.3 MB/s eta 0:01:17\n",
      "   ------------------ --------------------- 153.4/332.0 MB 2.3 MB/s eta 0:01:17\n",
      "   ------------------ --------------------- 153.9/332.0 MB 2.4 MB/s eta 0:01:16\n",
      "   ------------------ --------------------- 154.1/332.0 MB 2.4 MB/s eta 0:01:16\n",
      "   ------------------ --------------------- 154.4/332.0 MB 2.4 MB/s eta 0:01:15\n",
      "   ------------------ --------------------- 154.7/332.0 MB 2.4 MB/s eta 0:01:16\n",
      "   ------------------ --------------------- 154.9/332.0 MB 2.4 MB/s eta 0:01:16\n",
      "   ------------------ --------------------- 155.2/332.0 MB 2.4 MB/s eta 0:01:16\n",
      "   ------------------ --------------------- 155.7/332.0 MB 2.4 MB/s eta 0:01:15\n",
      "   ------------------ --------------------- 156.5/332.0 MB 2.4 MB/s eta 0:01:14\n",
      "   ------------------ --------------------- 157.0/332.0 MB 2.4 MB/s eta 0:01:13\n",
      "   ------------------- -------------------- 158.1/332.0 MB 2.4 MB/s eta 0:01:12\n",
      "   ------------------- -------------------- 159.4/332.0 MB 2.4 MB/s eta 0:01:11\n",
      "   ------------------- -------------------- 160.4/332.0 MB 2.5 MB/s eta 0:01:10\n",
      "   ------------------- -------------------- 161.5/332.0 MB 2.5 MB/s eta 0:01:09\n",
      "   ------------------- -------------------- 162.0/332.0 MB 2.5 MB/s eta 0:01:08\n",
      "   ------------------- -------------------- 162.8/332.0 MB 2.5 MB/s eta 0:01:08\n",
      "   ------------------- -------------------- 163.1/332.0 MB 2.5 MB/s eta 0:01:08\n",
      "   ------------------- -------------------- 163.8/332.0 MB 2.5 MB/s eta 0:01:07\n",
      "   ------------------- -------------------- 164.6/332.0 MB 2.5 MB/s eta 0:01:06\n",
      "   ------------------- -------------------- 165.4/332.0 MB 2.6 MB/s eta 0:01:05\n",
      "   ------------------- -------------------- 165.9/332.0 MB 2.6 MB/s eta 0:01:05\n",
      "   -------------------- ------------------- 166.2/332.0 MB 2.6 MB/s eta 0:01:05\n",
      "   -------------------- ------------------- 166.7/332.0 MB 2.6 MB/s eta 0:01:04\n",
      "   -------------------- ------------------- 167.5/332.0 MB 2.6 MB/s eta 0:01:04\n",
      "   -------------------- ------------------- 168.0/332.0 MB 2.6 MB/s eta 0:01:04\n",
      "   -------------------- ------------------- 168.6/332.0 MB 2.6 MB/s eta 0:01:03\n",
      "   -------------------- ------------------- 168.8/332.0 MB 2.6 MB/s eta 0:01:03\n",
      "   -------------------- ------------------- 169.3/332.0 MB 2.6 MB/s eta 0:01:03\n",
      "   -------------------- ------------------- 169.6/332.0 MB 2.6 MB/s eta 0:01:03\n",
      "   -------------------- ------------------- 170.1/332.0 MB 2.6 MB/s eta 0:01:02\n",
      "   -------------------- ------------------- 170.4/332.0 MB 2.6 MB/s eta 0:01:02\n",
      "   -------------------- ------------------- 170.9/332.0 MB 2.6 MB/s eta 0:01:02\n",
      "   -------------------- ------------------- 171.4/332.0 MB 2.6 MB/s eta 0:01:02\n",
      "   -------------------- ------------------- 171.7/332.0 MB 2.6 MB/s eta 0:01:01\n",
      "   -------------------- ------------------- 172.2/332.0 MB 2.6 MB/s eta 0:01:01\n",
      "   -------------------- ------------------- 172.8/332.0 MB 2.6 MB/s eta 0:01:01\n",
      "   -------------------- ------------------- 173.3/332.0 MB 2.6 MB/s eta 0:01:01\n",
      "   -------------------- ------------------- 173.5/332.0 MB 2.6 MB/s eta 0:01:01\n",
      "   -------------------- ------------------- 173.8/332.0 MB 2.6 MB/s eta 0:01:01\n",
      "   --------------------- ------------------ 174.3/332.0 MB 2.6 MB/s eta 0:01:01\n",
      "   --------------------- ------------------ 174.6/332.0 MB 2.6 MB/s eta 0:01:01\n",
      "   --------------------- ------------------ 175.1/332.0 MB 2.6 MB/s eta 0:01:00\n",
      "   --------------------- ------------------ 175.4/332.0 MB 2.6 MB/s eta 0:01:00\n",
      "   --------------------- ------------------ 175.9/332.0 MB 2.6 MB/s eta 0:01:00\n",
      "   --------------------- ------------------ 176.2/332.0 MB 2.6 MB/s eta 0:01:00\n",
      "   --------------------- ------------------ 176.4/332.0 MB 2.6 MB/s eta 0:00:59\n",
      "   --------------------- ------------------ 176.7/332.0 MB 2.6 MB/s eta 0:00:59\n",
      "   --------------------- ------------------ 176.9/332.0 MB 2.6 MB/s eta 0:00:59\n",
      "   --------------------- ------------------ 177.5/332.0 MB 2.6 MB/s eta 0:00:59\n",
      "   --------------------- ------------------ 178.0/332.0 MB 2.6 MB/s eta 0:00:59\n",
      "   --------------------- ------------------ 178.5/332.0 MB 2.6 MB/s eta 0:00:59\n",
      "   --------------------- ------------------ 178.5/332.0 MB 2.6 MB/s eta 0:00:59\n",
      "   --------------------- ------------------ 178.8/332.0 MB 2.6 MB/s eta 0:00:59\n",
      "   --------------------- ------------------ 179.3/332.0 MB 2.6 MB/s eta 0:00:58\n",
      "   --------------------- ------------------ 179.6/332.0 MB 2.6 MB/s eta 0:00:58\n",
      "   --------------------- ------------------ 180.1/332.0 MB 2.6 MB/s eta 0:00:58\n",
      "   --------------------- ------------------ 180.4/332.0 MB 2.6 MB/s eta 0:00:58\n",
      "   --------------------- ------------------ 180.9/332.0 MB 2.6 MB/s eta 0:00:58\n",
      "   --------------------- ------------------ 181.7/332.0 MB 2.6 MB/s eta 0:00:57\n",
      "   --------------------- ------------------ 182.5/332.0 MB 2.7 MB/s eta 0:00:57\n",
      "   ---------------------- ----------------- 183.0/332.0 MB 2.7 MB/s eta 0:00:57\n",
      "   ---------------------- ----------------- 183.5/332.0 MB 2.7 MB/s eta 0:00:56\n",
      "   ---------------------- ----------------- 183.8/332.0 MB 2.7 MB/s eta 0:00:56\n",
      "   ---------------------- ----------------- 184.0/332.0 MB 2.7 MB/s eta 0:00:56\n",
      "   ---------------------- ----------------- 184.3/332.0 MB 2.7 MB/s eta 0:00:56\n",
      "   ---------------------- ----------------- 184.8/332.0 MB 2.7 MB/s eta 0:00:56\n",
      "   ---------------------- ----------------- 185.3/332.0 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------------------- ----------------- 185.9/332.0 MB 2.7 MB/s eta 0:00:55\n",
      "   ---------------------- ----------------- 186.6/332.0 MB 2.7 MB/s eta 0:00:54\n",
      "   ---------------------- ----------------- 187.2/332.0 MB 2.7 MB/s eta 0:00:54\n",
      "   ---------------------- ----------------- 188.0/332.0 MB 2.7 MB/s eta 0:00:53\n",
      "   ---------------------- ----------------- 188.5/332.0 MB 2.7 MB/s eta 0:00:53\n",
      "   ---------------------- ----------------- 189.3/332.0 MB 2.7 MB/s eta 0:00:52\n",
      "   ---------------------- ----------------- 190.1/332.0 MB 2.8 MB/s eta 0:00:52\n",
      "   ---------------------- ----------------- 190.3/332.0 MB 2.8 MB/s eta 0:00:52\n",
      "   ---------------------- ----------------- 190.8/332.0 MB 2.8 MB/s eta 0:00:52\n",
      "   ----------------------- ---------------- 191.1/332.0 MB 2.8 MB/s eta 0:00:51\n",
      "   ----------------------- ---------------- 191.6/332.0 MB 2.8 MB/s eta 0:00:51\n",
      "   ----------------------- ---------------- 191.9/332.0 MB 2.8 MB/s eta 0:00:51\n",
      "   ----------------------- ---------------- 192.4/332.0 MB 2.8 MB/s eta 0:00:51\n",
      "   ----------------------- ---------------- 192.9/332.0 MB 2.8 MB/s eta 0:00:51\n",
      "   ----------------------- ---------------- 193.2/332.0 MB 2.8 MB/s eta 0:00:51\n",
      "   ----------------------- ---------------- 193.7/332.0 MB 2.8 MB/s eta 0:00:50\n",
      "   ----------------------- ---------------- 194.2/332.0 MB 2.8 MB/s eta 0:00:50\n",
      "   ----------------------- ---------------- 194.8/332.0 MB 2.8 MB/s eta 0:00:50\n",
      "   ----------------------- ---------------- 195.6/332.0 MB 2.8 MB/s eta 0:00:50\n",
      "   ----------------------- ---------------- 196.6/332.0 MB 2.8 MB/s eta 0:00:49\n",
      "   ----------------------- ---------------- 197.7/332.0 MB 2.8 MB/s eta 0:00:48\n",
      "   ----------------------- ---------------- 198.4/332.0 MB 2.8 MB/s eta 0:00:48\n",
      "   ----------------------- ---------------- 199.0/332.0 MB 2.8 MB/s eta 0:00:48\n",
      "   ------------------------ --------------- 200.0/332.0 MB 2.8 MB/s eta 0:00:48\n",
      "   ------------------------ --------------- 200.5/332.0 MB 2.8 MB/s eta 0:00:48\n",
      "   ------------------------ --------------- 201.1/332.0 MB 2.8 MB/s eta 0:00:47\n",
      "   ------------------------ --------------- 201.9/332.0 MB 2.8 MB/s eta 0:00:47\n",
      "   ------------------------ --------------- 202.6/332.0 MB 2.8 MB/s eta 0:00:47\n",
      "   ------------------------ --------------- 203.4/332.0 MB 2.8 MB/s eta 0:00:47\n",
      "   ------------------------ --------------- 204.5/332.0 MB 2.8 MB/s eta 0:00:47\n",
      "   ------------------------ --------------- 205.3/332.0 MB 2.8 MB/s eta 0:00:47\n",
      "   ------------------------ --------------- 206.0/332.0 MB 2.8 MB/s eta 0:00:46\n",
      "   ------------------------ --------------- 206.8/332.0 MB 2.8 MB/s eta 0:00:46\n",
      "   ------------------------- -------------- 207.9/332.0 MB 2.8 MB/s eta 0:00:45\n",
      "   ------------------------- -------------- 208.7/332.0 MB 2.8 MB/s eta 0:00:45\n",
      "   ------------------------- -------------- 209.5/332.0 MB 2.8 MB/s eta 0:00:44\n",
      "   ------------------------- -------------- 209.7/332.0 MB 2.8 MB/s eta 0:00:44\n",
      "   ------------------------- -------------- 210.0/332.0 MB 2.8 MB/s eta 0:00:44\n",
      "   ------------------------- -------------- 210.2/332.0 MB 2.8 MB/s eta 0:00:44\n",
      "   ------------------------- -------------- 210.2/332.0 MB 2.8 MB/s eta 0:00:44\n",
      "   ------------------------- -------------- 210.5/332.0 MB 2.7 MB/s eta 0:00:45\n",
      "   ------------------------- -------------- 210.8/332.0 MB 2.7 MB/s eta 0:00:45\n",
      "   ------------------------- -------------- 211.0/332.0 MB 2.7 MB/s eta 0:00:45\n",
      "   ------------------------- -------------- 211.6/332.0 MB 2.7 MB/s eta 0:00:45\n",
      "   ------------------------- -------------- 211.8/332.0 MB 2.7 MB/s eta 0:00:45\n",
      "   ------------------------- -------------- 212.3/332.0 MB 2.7 MB/s eta 0:00:44\n",
      "   ------------------------- -------------- 213.1/332.0 MB 2.7 MB/s eta 0:00:44\n",
      "   ------------------------- -------------- 213.6/332.0 MB 2.7 MB/s eta 0:00:44\n",
      "   ------------------------- -------------- 213.9/332.0 MB 2.7 MB/s eta 0:00:44\n",
      "   ------------------------- -------------- 213.9/332.0 MB 2.7 MB/s eta 0:00:44\n",
      "   ------------------------- -------------- 214.2/332.0 MB 2.7 MB/s eta 0:00:44\n",
      "   ------------------------- -------------- 214.7/332.0 MB 2.7 MB/s eta 0:00:45\n",
      "   ------------------------- -------------- 215.2/332.0 MB 2.7 MB/s eta 0:00:45\n",
      "   ------------------------- -------------- 215.5/332.0 MB 2.6 MB/s eta 0:00:45\n",
      "   ------------------------- -------------- 215.7/332.0 MB 2.6 MB/s eta 0:00:45\n",
      "   ------------------------- -------------- 215.7/332.0 MB 2.6 MB/s eta 0:00:45\n",
      "   -------------------------- ------------- 216.0/332.0 MB 2.6 MB/s eta 0:00:45\n",
      "   -------------------------- ------------- 216.3/332.0 MB 2.6 MB/s eta 0:00:45\n",
      "   -------------------------- ------------- 216.8/332.0 MB 2.6 MB/s eta 0:00:45\n",
      "   -------------------------- ------------- 217.3/332.0 MB 2.6 MB/s eta 0:00:45\n",
      "   -------------------------- ------------- 217.6/332.0 MB 2.6 MB/s eta 0:00:45\n",
      "   -------------------------- ------------- 218.1/332.0 MB 2.5 MB/s eta 0:00:46\n",
      "   -------------------------- ------------- 218.4/332.0 MB 2.5 MB/s eta 0:00:46\n",
      "   -------------------------- ------------- 218.6/332.0 MB 2.5 MB/s eta 0:00:46\n",
      "   -------------------------- ------------- 218.9/332.0 MB 2.5 MB/s eta 0:00:46\n",
      "   -------------------------- ------------- 219.2/332.0 MB 2.5 MB/s eta 0:00:46\n",
      "   -------------------------- ------------- 219.4/332.0 MB 2.5 MB/s eta 0:00:46\n",
      "   -------------------------- ------------- 219.7/332.0 MB 2.5 MB/s eta 0:00:46\n",
      "   -------------------------- ------------- 219.9/332.0 MB 2.5 MB/s eta 0:00:46\n",
      "   -------------------------- ------------- 220.2/332.0 MB 2.5 MB/s eta 0:00:46\n",
      "   -------------------------- ------------- 220.5/332.0 MB 2.4 MB/s eta 0:00:46\n",
      "   -------------------------- ------------- 221.0/332.0 MB 2.4 MB/s eta 0:00:46\n",
      "   -------------------------- ------------- 221.2/332.0 MB 2.4 MB/s eta 0:00:46\n",
      "   -------------------------- ------------- 221.5/332.0 MB 2.4 MB/s eta 0:00:46\n",
      "   -------------------------- ------------- 222.0/332.0 MB 2.4 MB/s eta 0:00:46\n",
      "   -------------------------- ------------- 222.3/332.0 MB 2.4 MB/s eta 0:00:46\n",
      "   -------------------------- ------------- 222.8/332.0 MB 2.4 MB/s eta 0:00:46\n",
      "   -------------------------- ------------- 223.1/332.0 MB 2.4 MB/s eta 0:00:46\n",
      "   -------------------------- ------------- 223.3/332.0 MB 2.4 MB/s eta 0:00:47\n",
      "   -------------------------- ------------- 223.6/332.0 MB 2.4 MB/s eta 0:00:47\n",
      "   -------------------------- ------------- 223.9/332.0 MB 2.3 MB/s eta 0:00:47\n",
      "   --------------------------- ------------ 224.1/332.0 MB 2.3 MB/s eta 0:00:47\n",
      "   --------------------------- ------------ 224.4/332.0 MB 2.3 MB/s eta 0:00:46\n",
      "   --------------------------- ------------ 224.7/332.0 MB 2.3 MB/s eta 0:00:46\n",
      "   --------------------------- ------------ 224.9/332.0 MB 2.3 MB/s eta 0:00:46\n",
      "   --------------------------- ------------ 225.4/332.0 MB 2.3 MB/s eta 0:00:46\n",
      "   --------------------------- ------------ 226.0/332.0 MB 2.3 MB/s eta 0:00:46\n",
      "   --------------------------- ------------ 226.2/332.0 MB 2.3 MB/s eta 0:00:46\n",
      "   --------------------------- ------------ 226.5/332.0 MB 2.3 MB/s eta 0:00:46\n",
      "   --------------------------- ------------ 226.8/332.0 MB 2.3 MB/s eta 0:00:46\n",
      "   --------------------------- ------------ 227.0/332.0 MB 2.3 MB/s eta 0:00:46\n",
      "   --------------------------- ------------ 227.5/332.0 MB 2.2 MB/s eta 0:00:47\n",
      "   --------------------------- ------------ 227.8/332.0 MB 2.2 MB/s eta 0:00:47\n",
      "   --------------------------- ------------ 228.1/332.0 MB 2.2 MB/s eta 0:00:47\n",
      "   --------------------------- ------------ 228.6/332.0 MB 2.2 MB/s eta 0:00:47\n",
      "   --------------------------- ------------ 228.9/332.0 MB 2.2 MB/s eta 0:00:47\n",
      "   --------------------------- ------------ 229.6/332.0 MB 2.2 MB/s eta 0:00:47\n",
      "   --------------------------- ------------ 230.2/332.0 MB 2.2 MB/s eta 0:00:47\n",
      "   --------------------------- ------------ 230.4/332.0 MB 2.2 MB/s eta 0:00:47\n",
      "   --------------------------- ------------ 230.9/332.0 MB 2.2 MB/s eta 0:00:47\n",
      "   --------------------------- ------------ 231.5/332.0 MB 2.2 MB/s eta 0:00:47\n",
      "   --------------------------- ------------ 231.7/332.0 MB 2.2 MB/s eta 0:00:47\n",
      "   --------------------------- ------------ 232.0/332.0 MB 2.2 MB/s eta 0:00:47\n",
      "   ---------------------------- ----------- 232.5/332.0 MB 2.2 MB/s eta 0:00:47\n",
      "   ---------------------------- ----------- 232.8/332.0 MB 2.2 MB/s eta 0:00:46\n",
      "   ---------------------------- ----------- 233.3/332.0 MB 2.2 MB/s eta 0:00:46\n",
      "   ---------------------------- ----------- 233.8/332.0 MB 2.2 MB/s eta 0:00:46\n",
      "   ---------------------------- ----------- 234.1/332.0 MB 2.2 MB/s eta 0:00:46\n",
      "   ---------------------------- ----------- 234.4/332.0 MB 2.2 MB/s eta 0:00:46\n",
      "   ---------------------------- ----------- 234.9/332.0 MB 2.2 MB/s eta 0:00:46\n",
      "   ---------------------------- ----------- 235.1/332.0 MB 2.1 MB/s eta 0:00:46\n",
      "   ---------------------------- ----------- 235.7/332.0 MB 2.1 MB/s eta 0:00:45\n",
      "   ---------------------------- ----------- 236.2/332.0 MB 2.2 MB/s eta 0:00:45\n",
      "   ---------------------------- ----------- 236.5/332.0 MB 2.2 MB/s eta 0:00:45\n",
      "   ---------------------------- ----------- 237.0/332.0 MB 2.1 MB/s eta 0:00:45\n",
      "   ---------------------------- ----------- 237.5/332.0 MB 2.1 MB/s eta 0:00:45\n",
      "   ---------------------------- ----------- 238.0/332.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 238.3/332.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 238.6/332.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 238.8/332.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 239.1/332.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 239.1/332.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 239.6/332.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 239.9/332.0 MB 2.1 MB/s eta 0:00:44\n",
      "   ---------------------------- ----------- 240.4/332.0 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 240.9/332.0 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 241.4/332.0 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 241.7/332.0 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 242.0/332.0 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 242.2/332.0 MB 2.1 MB/s eta 0:00:42\n",
      "   ----------------------------- ---------- 242.7/332.0 MB 2.1 MB/s eta 0:00:42\n",
      "   ----------------------------- ---------- 243.0/332.0 MB 2.1 MB/s eta 0:00:42\n",
      "   ----------------------------- ---------- 243.5/332.0 MB 2.1 MB/s eta 0:00:42\n",
      "   ----------------------------- ---------- 243.8/332.0 MB 2.1 MB/s eta 0:00:42\n",
      "   ----------------------------- ---------- 244.3/332.0 MB 2.1 MB/s eta 0:00:41\n",
      "   ----------------------------- ---------- 244.6/332.0 MB 2.1 MB/s eta 0:00:41\n",
      "   ----------------------------- ---------- 245.1/332.0 MB 2.1 MB/s eta 0:00:41\n",
      "   ----------------------------- ---------- 245.4/332.0 MB 2.1 MB/s eta 0:00:41\n",
      "   ----------------------------- ---------- 245.6/332.0 MB 2.1 MB/s eta 0:00:41\n",
      "   ----------------------------- ---------- 246.2/332.0 MB 2.1 MB/s eta 0:00:41\n",
      "   ----------------------------- ---------- 246.4/332.0 MB 2.1 MB/s eta 0:00:41\n",
      "   ----------------------------- ---------- 246.9/332.0 MB 2.1 MB/s eta 0:00:41\n",
      "   ----------------------------- ---------- 247.7/332.0 MB 2.1 MB/s eta 0:00:40\n",
      "   ----------------------------- ---------- 248.5/332.0 MB 2.1 MB/s eta 0:00:40\n",
      "   ------------------------------ --------- 249.3/332.0 MB 2.2 MB/s eta 0:00:39\n",
      "   ------------------------------ --------- 250.1/332.0 MB 2.2 MB/s eta 0:00:38\n",
      "   ------------------------------ --------- 250.6/332.0 MB 2.2 MB/s eta 0:00:38\n",
      "   ------------------------------ --------- 250.9/332.0 MB 2.1 MB/s eta 0:00:38\n",
      "   ------------------------------ --------- 251.7/332.0 MB 2.2 MB/s eta 0:00:38\n",
      "   ------------------------------ --------- 252.2/332.0 MB 2.1 MB/s eta 0:00:38\n",
      "   ------------------------------ --------- 252.7/332.0 MB 2.1 MB/s eta 0:00:38\n",
      "   ------------------------------ --------- 253.2/332.0 MB 2.1 MB/s eta 0:00:37\n",
      "   ------------------------------ --------- 253.5/332.0 MB 2.1 MB/s eta 0:00:38\n",
      "   ------------------------------ --------- 254.0/332.0 MB 2.1 MB/s eta 0:00:37\n",
      "   ------------------------------ --------- 254.5/332.0 MB 2.1 MB/s eta 0:00:37\n",
      "   ------------------------------ --------- 255.3/332.0 MB 2.1 MB/s eta 0:00:36\n",
      "   ------------------------------ --------- 255.9/332.0 MB 2.1 MB/s eta 0:00:36\n",
      "   ------------------------------ --------- 256.1/332.0 MB 2.1 MB/s eta 0:00:36\n",
      "   ------------------------------ --------- 256.4/332.0 MB 2.1 MB/s eta 0:00:36\n",
      "   ------------------------------ --------- 256.9/332.0 MB 2.1 MB/s eta 0:00:36\n",
      "   ------------------------------- -------- 257.7/332.0 MB 2.2 MB/s eta 0:00:35\n",
      "   ------------------------------- -------- 258.2/332.0 MB 2.2 MB/s eta 0:00:35\n",
      "   ------------------------------- -------- 258.5/332.0 MB 2.2 MB/s eta 0:00:35\n",
      "   ------------------------------- -------- 259.0/332.0 MB 2.1 MB/s eta 0:00:35\n",
      "   ------------------------------- -------- 259.5/332.0 MB 2.1 MB/s eta 0:00:34\n",
      "   ------------------------------- -------- 259.8/332.0 MB 2.1 MB/s eta 0:00:35\n",
      "   ------------------------------- -------- 260.3/332.0 MB 2.1 MB/s eta 0:00:35\n",
      "   ------------------------------- -------- 260.6/332.0 MB 2.1 MB/s eta 0:00:35\n",
      "   ------------------------------- -------- 261.1/332.0 MB 2.1 MB/s eta 0:00:35\n",
      "   ------------------------------- -------- 261.4/332.0 MB 2.1 MB/s eta 0:00:35\n",
      "   ------------------------------- -------- 261.9/332.0 MB 2.1 MB/s eta 0:00:35\n",
      "   ------------------------------- -------- 262.1/332.0 MB 2.0 MB/s eta 0:00:35\n",
      "   ------------------------------- -------- 262.4/332.0 MB 2.0 MB/s eta 0:00:35\n",
      "   ------------------------------- -------- 262.9/332.0 MB 2.0 MB/s eta 0:00:35\n",
      "   ------------------------------- -------- 263.2/332.0 MB 2.0 MB/s eta 0:00:35\n",
      "   ------------------------------- -------- 263.5/332.0 MB 2.0 MB/s eta 0:00:35\n",
      "   ------------------------------- -------- 264.0/332.0 MB 2.0 MB/s eta 0:00:35\n",
      "   ------------------------------- -------- 264.2/332.0 MB 2.0 MB/s eta 0:00:35\n",
      "   ------------------------------- -------- 264.8/332.0 MB 1.9 MB/s eta 0:00:35\n",
      "   ------------------------------- -------- 265.6/332.0 MB 1.9 MB/s eta 0:00:35\n",
      "   -------------------------------- ------- 266.3/332.0 MB 1.9 MB/s eta 0:00:34\n",
      "   -------------------------------- ------- 266.9/332.0 MB 1.9 MB/s eta 0:00:34\n",
      "   -------------------------------- ------- 267.4/332.0 MB 1.9 MB/s eta 0:00:34\n",
      "   -------------------------------- ------- 267.9/332.0 MB 1.9 MB/s eta 0:00:34\n",
      "   -------------------------------- ------- 267.9/332.0 MB 1.9 MB/s eta 0:00:34\n",
      "   -------------------------------- ------- 268.2/332.0 MB 1.9 MB/s eta 0:00:34\n",
      "   -------------------------------- ------- 268.4/332.0 MB 1.9 MB/s eta 0:00:33\n",
      "   -------------------------------- ------- 268.7/332.0 MB 1.9 MB/s eta 0:00:33\n",
      "   -------------------------------- ------- 269.2/332.0 MB 1.9 MB/s eta 0:00:33\n",
      "   -------------------------------- ------- 269.5/332.0 MB 1.9 MB/s eta 0:00:33\n",
      "   -------------------------------- ------- 270.0/332.0 MB 1.9 MB/s eta 0:00:32\n",
      "   -------------------------------- ------- 270.8/332.0 MB 2.0 MB/s eta 0:00:32\n",
      "   -------------------------------- ------- 271.6/332.0 MB 2.0 MB/s eta 0:00:31\n",
      "   -------------------------------- ------- 272.6/332.0 MB 2.0 MB/s eta 0:00:31\n",
      "   -------------------------------- ------- 272.9/332.0 MB 2.0 MB/s eta 0:00:30\n",
      "   -------------------------------- ------- 273.7/332.0 MB 2.0 MB/s eta 0:00:30\n",
      "   --------------------------------- ------ 274.5/332.0 MB 2.0 MB/s eta 0:00:29\n",
      "   --------------------------------- ------ 275.0/332.0 MB 2.0 MB/s eta 0:00:29\n",
      "   --------------------------------- ------ 275.5/332.0 MB 2.0 MB/s eta 0:00:29\n",
      "   --------------------------------- ------ 275.8/332.0 MB 2.0 MB/s eta 0:00:28\n",
      "   --------------------------------- ------ 276.0/332.0 MB 2.0 MB/s eta 0:00:28\n",
      "   --------------------------------- ------ 276.3/332.0 MB 2.0 MB/s eta 0:00:28\n",
      "   --------------------------------- ------ 276.6/332.0 MB 2.0 MB/s eta 0:00:28\n",
      "   --------------------------------- ------ 276.8/332.0 MB 2.0 MB/s eta 0:00:28\n",
      "   --------------------------------- ------ 277.1/332.0 MB 2.0 MB/s eta 0:00:28\n",
      "   --------------------------------- ------ 277.6/332.0 MB 2.0 MB/s eta 0:00:28\n",
      "   --------------------------------- ------ 277.9/332.0 MB 2.0 MB/s eta 0:00:27\n",
      "   --------------------------------- ------ 278.1/332.0 MB 2.0 MB/s eta 0:00:27\n",
      "   --------------------------------- ------ 278.7/332.0 MB 2.0 MB/s eta 0:00:27\n",
      "   --------------------------------- ------ 279.2/332.0 MB 2.0 MB/s eta 0:00:27\n",
      "   --------------------------------- ------ 279.7/332.0 MB 2.0 MB/s eta 0:00:26\n",
      "   --------------------------------- ------ 280.2/332.0 MB 2.0 MB/s eta 0:00:26\n",
      "   --------------------------------- ------ 280.5/332.0 MB 2.0 MB/s eta 0:00:26\n",
      "   --------------------------------- ------ 280.8/332.0 MB 2.0 MB/s eta 0:00:26\n",
      "   --------------------------------- ------ 281.0/332.0 MB 2.0 MB/s eta 0:00:26\n",
      "   --------------------------------- ------ 281.3/332.0 MB 2.0 MB/s eta 0:00:25\n",
      "   --------------------------------- ------ 281.8/332.0 MB 2.0 MB/s eta 0:00:25\n",
      "   --------------------------------- ------ 282.1/332.0 MB 2.0 MB/s eta 0:00:25\n",
      "   ---------------------------------- ----- 282.3/332.0 MB 2.0 MB/s eta 0:00:25\n",
      "   ---------------------------------- ----- 282.9/332.0 MB 2.0 MB/s eta 0:00:25\n",
      "   ---------------------------------- ----- 283.4/332.0 MB 2.0 MB/s eta 0:00:24\n",
      "   ---------------------------------- ----- 283.9/332.0 MB 2.0 MB/s eta 0:00:24\n",
      "   ---------------------------------- ----- 284.2/332.0 MB 2.0 MB/s eta 0:00:24\n",
      "   ---------------------------------- ----- 284.2/332.0 MB 2.0 MB/s eta 0:00:24\n",
      "   ---------------------------------- ----- 284.4/332.0 MB 2.0 MB/s eta 0:00:24\n",
      "   ---------------------------------- ----- 285.0/332.0 MB 2.0 MB/s eta 0:00:24\n",
      "   ---------------------------------- ----- 285.2/332.0 MB 2.0 MB/s eta 0:00:23\n",
      "   ---------------------------------- ----- 285.7/332.0 MB 2.1 MB/s eta 0:00:23\n",
      "   ---------------------------------- ----- 286.3/332.0 MB 2.1 MB/s eta 0:00:23\n",
      "   ---------------------------------- ----- 287.0/332.0 MB 2.1 MB/s eta 0:00:22\n",
      "   ---------------------------------- ----- 288.1/332.0 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------------------- ----- 288.9/332.0 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------------------- ----- 289.7/332.0 MB 2.1 MB/s eta 0:00:20\n",
      "   ----------------------------------- ---- 290.7/332.0 MB 2.1 MB/s eta 0:00:20\n",
      "   ----------------------------------- ---- 291.8/332.0 MB 2.2 MB/s eta 0:00:19\n",
      "   ----------------------------------- ---- 292.6/332.0 MB 2.2 MB/s eta 0:00:19\n",
      "   ----------------------------------- ---- 292.8/332.0 MB 2.2 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 293.6/332.0 MB 2.2 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 294.4/332.0 MB 2.2 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 295.2/332.0 MB 2.2 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 296.0/332.0 MB 2.2 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 296.5/332.0 MB 2.2 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 297.0/332.0 MB 2.2 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 297.5/332.0 MB 2.2 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 297.8/332.0 MB 2.2 MB/s eta 0:00:16\n",
      "   ----------------------------------- ---- 298.3/332.0 MB 2.2 MB/s eta 0:00:16\n",
      "   ------------------------------------ --- 298.8/332.0 MB 2.2 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 299.1/332.0 MB 2.2 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 299.4/332.0 MB 2.2 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 299.6/332.0 MB 2.2 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 299.9/332.0 MB 2.2 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 300.2/332.0 MB 2.2 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 300.7/332.0 MB 2.2 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 301.2/332.0 MB 2.2 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 301.7/332.0 MB 2.2 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 302.3/332.0 MB 2.2 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 303.0/332.0 MB 2.3 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 303.8/332.0 MB 2.3 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 304.6/332.0 MB 2.3 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 305.4/332.0 MB 2.3 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 305.9/332.0 MB 2.3 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 306.4/332.0 MB 2.3 MB/s eta 0:00:12\n",
      "   ------------------------------------- -- 307.2/332.0 MB 2.3 MB/s eta 0:00:11\n",
      "   ------------------------------------- -- 307.8/332.0 MB 2.3 MB/s eta 0:00:11\n",
      "   ------------------------------------- -- 308.0/332.0 MB 2.3 MB/s eta 0:00:11\n",
      "   ------------------------------------- -- 308.8/332.0 MB 2.3 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 309.1/332.0 MB 2.4 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 309.6/332.0 MB 2.3 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 310.1/332.0 MB 2.3 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 310.4/332.0 MB 2.3 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 310.9/332.0 MB 2.3 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 311.4/332.0 MB 2.3 MB/s eta 0:00:09\n",
      "   ------------------------------------- -- 312.2/332.0 MB 2.4 MB/s eta 0:00:09\n",
      "   ------------------------------------- -- 313.0/332.0 MB 2.4 MB/s eta 0:00:09\n",
      "   ------------------------------------- -- 313.5/332.0 MB 2.4 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 314.0/332.0 MB 2.4 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 314.6/332.0 MB 2.4 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 315.4/332.0 MB 2.4 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 316.1/332.0 MB 2.4 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 316.9/332.0 MB 2.4 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 317.7/332.0 MB 2.5 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 318.2/332.0 MB 2.5 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 319.0/332.0 MB 2.5 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 319.3/332.0 MB 2.5 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 319.8/332.0 MB 2.5 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 320.1/332.0 MB 2.5 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 320.6/332.0 MB 2.5 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 320.6/332.0 MB 2.5 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 320.9/332.0 MB 2.5 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 321.4/332.0 MB 2.4 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 321.7/332.0 MB 2.4 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 321.9/332.0 MB 2.4 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 322.2/332.0 MB 2.4 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 322.2/332.0 MB 2.4 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 322.4/332.0 MB 2.4 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 322.7/332.0 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 323.0/332.0 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 323.2/332.0 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 323.5/332.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------------------------------  323.7/332.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------------------------------  324.3/332.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------------------------------  324.5/332.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------------------------------  324.5/332.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------------------------------  324.8/332.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------------------------------  325.1/332.0 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------------------------------  325.6/332.0 MB 2.3 MB/s eta 0:00:03\n",
      "   ---------------------------------------  325.8/332.0 MB 2.3 MB/s eta 0:00:03\n",
      "   ---------------------------------------  326.1/332.0 MB 2.3 MB/s eta 0:00:03\n",
      "   ---------------------------------------  326.6/332.0 MB 2.3 MB/s eta 0:00:03\n",
      "   ---------------------------------------  327.2/332.0 MB 2.3 MB/s eta 0:00:03\n",
      "   ---------------------------------------  327.4/332.0 MB 2.3 MB/s eta 0:00:03\n",
      "   ---------------------------------------  328.2/332.0 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------------------  328.7/332.0 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------------------  329.0/332.0 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------------------  329.5/332.0 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------------------  330.6/332.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.1/332.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.4/332.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.6/332.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/332.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/332.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 332.0/332.0 MB 2.3 MB/s  0:02:47\n",
      "Using cached grpcio-1.74.0-cp313-cp313-win_amd64.whl (4.5 MB)\n",
      "Using cached ml_dtypes-0.5.3-cp313-cp313-win_amd64.whl (208 kB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached h5py-3.14.0-cp313-cp313-win_amd64.whl (2.9 MB)\n",
      "Downloading keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.4 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.5/1.4 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.8/1.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.3/1.4 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 1.7 MB/s  0:00:00\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Downloading markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Using cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached wrapt-1.17.3-cp313-cp313-win_amd64.whl (38 kB)\n",
      "Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached optree-0.17.0-cp313-cp313-win_amd64.whl (316 kB)\n",
      "Using cached rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt_einsum, ml_dtypes, mdurl, markdown, h5py, grpcio, google_pasta, gast, absl-py, tensorboard, markdown-it-py, astunparse, rich, keras, tensorflow\n",
      "\n",
      "   - --------------------------------------  1/25 [libclang]\n",
      "   - --------------------------------------  1/25 [libclang]\n",
      "   --- ------------------------------------  2/25 [flatbuffers]\n",
      "   ------ ---------------------------------  4/25 [wheel]\n",
      "   ------ ---------------------------------  4/25 [wheel]\n",
      "   ------ ---------------------------------  4/25 [wheel]\n",
      "   -------- -------------------------------  5/25 [werkzeug]\n",
      "   -------- -------------------------------  5/25 [werkzeug]\n",
      "   -------- -------------------------------  5/25 [werkzeug]\n",
      "   -------- -------------------------------  5/25 [werkzeug]\n",
      "   --------- ------------------------------  6/25 [termcolor]\n",
      "   ------------ ---------------------------  8/25 [protobuf]\n",
      "   ------------ ---------------------------  8/25 [protobuf]\n",
      "   ------------ ---------------------------  8/25 [protobuf]\n",
      "   ------------ ---------------------------  8/25 [protobuf]\n",
      "   ------------ ---------------------------  8/25 [protobuf]\n",
      "   -------------- -------------------------  9/25 [optree]\n",
      "   -------------- -------------------------  9/25 [optree]\n",
      "   ---------------- ----------------------- 10/25 [opt_einsum]\n",
      "   ---------------- ----------------------- 10/25 [opt_einsum]\n",
      "   -------------------- ------------------- 13/25 [markdown]\n",
      "   -------------------- ------------------- 13/25 [markdown]\n",
      "   -------------------- ------------------- 13/25 [markdown]\n",
      "   ---------------------- ----------------- 14/25 [h5py]\n",
      "   ---------------------- ----------------- 14/25 [h5py]\n",
      "   ---------------------- ----------------- 14/25 [h5py]\n",
      "   ---------------------- ----------------- 14/25 [h5py]\n",
      "   ---------------------- ----------------- 14/25 [h5py]\n",
      "   ------------------------ --------------- 15/25 [grpcio]\n",
      "   ------------------------ --------------- 15/25 [grpcio]\n",
      "   ------------------------ --------------- 15/25 [grpcio]\n",
      "   ------------------------ --------------- 15/25 [grpcio]\n",
      "   ------------------------- -------------- 16/25 [google_pasta]\n",
      "   --------------------------- ------------ 17/25 [gast]\n",
      "   ---------------------------- ----------- 18/25 [absl-py]\n",
      "   ---------------------------- ----------- 18/25 [absl-py]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   ------------------------------ --------- 19/25 [tensorboard]\n",
      "   -------------------------------- ------- 20/25 [markdown-it-py]\n",
      "   -------------------------------- ------- 20/25 [markdown-it-py]\n",
      "   -------------------------------- ------- 20/25 [markdown-it-py]\n",
      "   -------------------------------- ------- 20/25 [markdown-it-py]\n",
      "   ----------------------------------- ---- 22/25 [rich]\n",
      "   ----------------------------------- ---- 22/25 [rich]\n",
      "   ----------------------------------- ---- 22/25 [rich]\n",
      "   ----------------------------------- ---- 22/25 [rich]\n",
      "   ----------------------------------- ---- 22/25 [rich]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   ------------------------------------ --- 23/25 [keras]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   -------------------------------------- - 24/25 [tensorflow]\n",
      "   ---------------------------------------- 25/25 [tensorflow]\n",
      "\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google_pasta-0.2.0 grpcio-1.74.0 h5py-3.14.0 keras-3.11.3 libclang-18.1.1 markdown-3.9 markdown-it-py-4.0.0 mdurl-0.1.2 ml_dtypes-0.5.3 namex-0.1.0 opt_einsum-3.4.0 optree-0.17.0 protobuf-6.32.1 rich-14.1.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n",
      "Keras version: 3.11.3\n",
      "TensorFlow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Set random seed for reproducability\n",
    "tensorflow.random.set_seed(0)\n",
    "\n",
    "print(\"Libraries imported.\")\n",
    "print('Keras version:',keras.__version__)\n",
    "print('TensorFlow version:',tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for TensorFlow\n",
    "\n",
    "We've already loaded our data and split it into training and validation datasets. However, we need to do some further data preparation so that our data will work correctly with TensorFlow. Specifically, we need to set the data type of our features to 32-bit floating point numbers, and specify that the labels represent categorical classes rather than numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready...\n"
     ]
    }
   ],
   "source": [
    "# Set data types for float features\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Set data types for categorical labels\n",
    "y_train = utils.to_categorical(y_train)\n",
    "y_test = utils.to_categorical(y_test)\n",
    "print('Ready...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a neural network\n",
    "\n",
    "Now we're ready to define our neural network. In this case, we'll create a network that consists of 3 fully-connected layers:\n",
    "* An input layer that receives an input value for each feature (in this case, the four penguin measurements) and applies a *ReLU* activation function.\n",
    "* A hidden layer that receives ten inputs and applies a *ReLU* activation function.\n",
    "* An output layer that uses a *SoftMax* activation function to generate an output for each penguin species (which represent the classification probabilities for each of the three possible penguin species). Softmax functions produce a vector with probability values that sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Workspace\\Python\\Azure\\ml-basics\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âââââââââââââââââââââââââââââââââââ³âââââââââââââââââââââââââ³ââââââââââââââââ\n",
       "â<span style=\"font-weight: bold\"> Layer (type)                    </span>â<span style=\"font-weight: bold\"> Output Shape           </span>â<span style=\"font-weight: bold\">       Param # </span>â\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â            <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â           <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              â            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â\n",
       "âââââââââââââââââââââââââââââââââââ´âââââââââââââââââââââââââ´ââââââââââââââââ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âââââââââââââââââââââââââââââââââââ³âââââââââââââââââââââââââ³ââââââââââââââââ\n",
       "â\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â dense (\u001b[38;5;33mDense\u001b[0m)                   â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â            \u001b[38;5;34m50\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â           \u001b[38;5;34m110\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              â            \u001b[38;5;34m33\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ´âââââââââââââââââââââââââ´ââââââââââââââââ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193</span> (772.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m193\u001b[0m (772.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193</span> (772.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m193\u001b[0m (772.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define a classifier network\n",
    "hl = 10 # Number of hidden layer nodes\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(hl, input_dim=len(features), activation='relu'))\n",
    "model.add(Dense(hl, input_dim=hl, activation='relu'))\n",
    "model.add(Dense(len(penguin_classes), input_dim=hl, activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "To train the model, we need to repeatedly feed the training values forward through the network, use a loss function to calculate the loss, use an optimizer to backpropagate the weight and bias value adjustments, and validate the model using the test data we withheld.\n",
    "\n",
    "To do this, we'll apply an Adam optimizer to a categorical cross-entropy loss function iteratively over 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4702 - loss: 10.7161 - val_accuracy: 0.5718 - val_loss: 4.1220\n",
      "Epoch 2/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2560 - loss: 1.5745 - val_accuracy: 0.2214 - val_loss: 1.0921\n",
      "Epoch 3/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2393 - loss: 0.9933 - val_accuracy: 0.4331 - val_loss: 0.9170\n",
      "Epoch 4/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6050 - loss: 0.8243 - val_accuracy: 0.7956 - val_loss: 0.7600\n",
      "Epoch 5/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8109 - loss: 0.6771 - val_accuracy: 0.8637 - val_loss: 0.6268\n",
      "Epoch 6/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8757 - loss: 0.5591 - val_accuracy: 0.9027 - val_loss: 0.5224\n",
      "Epoch 7/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9070 - loss: 0.4675 - val_accuracy: 0.9002 - val_loss: 0.4420\n",
      "Epoch 8/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.3968 - val_accuracy: 0.9319 - val_loss: 0.3793\n",
      "Epoch 9/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9363 - loss: 0.3414 - val_accuracy: 0.9489 - val_loss: 0.3293\n",
      "Epoch 10/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9425 - loss: 0.2968 - val_accuracy: 0.9513 - val_loss: 0.2885\n",
      "Epoch 11/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9488 - loss: 0.2602 - val_accuracy: 0.9562 - val_loss: 0.2548\n",
      "Epoch 12/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9561 - loss: 0.2300 - val_accuracy: 0.9611 - val_loss: 0.2267\n",
      "Epoch 13/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9624 - loss: 0.2047 - val_accuracy: 0.9635 - val_loss: 0.2029\n",
      "Epoch 14/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9666 - loss: 0.1835 - val_accuracy: 0.9732 - val_loss: 0.1827\n",
      "Epoch 15/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9687 - loss: 0.1654 - val_accuracy: 0.9805 - val_loss: 0.1654\n",
      "Epoch 16/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9728 - loss: 0.1500 - val_accuracy: 0.9805 - val_loss: 0.1505\n",
      "Epoch 17/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9739 - loss: 0.1368 - val_accuracy: 0.9805 - val_loss: 0.1376\n",
      "Epoch 18/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9739 - loss: 0.1254 - val_accuracy: 0.9854 - val_loss: 0.1263\n",
      "Epoch 19/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9770 - loss: 0.1155 - val_accuracy: 0.9854 - val_loss: 0.1164\n",
      "Epoch 20/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9781 - loss: 0.1067 - val_accuracy: 0.9903 - val_loss: 0.1077\n",
      "Epoch 21/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9791 - loss: 0.0991 - val_accuracy: 0.9903 - val_loss: 0.1001\n",
      "Epoch 22/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9822 - loss: 0.0923 - val_accuracy: 0.9903 - val_loss: 0.0933\n",
      "Epoch 23/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9822 - loss: 0.0864 - val_accuracy: 0.9903 - val_loss: 0.0872\n",
      "Epoch 24/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9822 - loss: 0.0810 - val_accuracy: 0.9903 - val_loss: 0.0818\n",
      "Epoch 25/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9822 - loss: 0.0763 - val_accuracy: 0.9903 - val_loss: 0.0770\n",
      "Epoch 26/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9833 - loss: 0.0720 - val_accuracy: 0.9903 - val_loss: 0.0726\n",
      "Epoch 27/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9843 - loss: 0.0681 - val_accuracy: 0.9903 - val_loss: 0.0687\n",
      "Epoch 28/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9864 - loss: 0.0646 - val_accuracy: 0.9903 - val_loss: 0.0651\n",
      "Epoch 29/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9864 - loss: 0.0615 - val_accuracy: 0.9951 - val_loss: 0.0618\n",
      "Epoch 30/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9864 - loss: 0.0586 - val_accuracy: 0.9951 - val_loss: 0.0589\n",
      "Epoch 31/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9875 - loss: 0.0560 - val_accuracy: 0.9951 - val_loss: 0.0561\n",
      "Epoch 32/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9885 - loss: 0.0536 - val_accuracy: 0.9951 - val_loss: 0.0536\n",
      "Epoch 33/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9885 - loss: 0.0514 - val_accuracy: 0.9951 - val_loss: 0.0513\n",
      "Epoch 34/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9896 - loss: 0.0494 - val_accuracy: 0.9951 - val_loss: 0.0492\n",
      "Epoch 35/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9896 - loss: 0.0475 - val_accuracy: 0.9951 - val_loss: 0.0472\n",
      "Epoch 36/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9896 - loss: 0.0458 - val_accuracy: 0.9951 - val_loss: 0.0453\n",
      "Epoch 37/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9906 - loss: 0.0441 - val_accuracy: 0.9951 - val_loss: 0.0436\n",
      "Epoch 38/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9906 - loss: 0.0427 - val_accuracy: 0.9951 - val_loss: 0.0421\n",
      "Epoch 39/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9896 - loss: 0.0411 - val_accuracy: 0.9951 - val_loss: 0.0405\n",
      "Epoch 40/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9896 - loss: 0.0398 - val_accuracy: 0.9951 - val_loss: 0.0391\n",
      "Epoch 41/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9896 - loss: 0.0386 - val_accuracy: 0.9951 - val_loss: 0.0379\n",
      "Epoch 42/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9896 - loss: 0.0375 - val_accuracy: 0.9951 - val_loss: 0.0367\n",
      "Epoch 43/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9927 - loss: 0.0365 - val_accuracy: 0.9951 - val_loss: 0.0355\n",
      "Epoch 44/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9916 - loss: 0.0355 - val_accuracy: 0.9951 - val_loss: 0.0344\n",
      "Epoch 45/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9916 - loss: 0.0345 - val_accuracy: 0.9951 - val_loss: 0.0335\n",
      "Epoch 46/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9916 - loss: 0.0337 - val_accuracy: 0.9951 - val_loss: 0.0325\n",
      "Epoch 47/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9916 - loss: 0.0328 - val_accuracy: 0.9951 - val_loss: 0.0316\n",
      "Epoch 48/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9916 - loss: 0.0320 - val_accuracy: 0.9951 - val_loss: 0.0307\n",
      "Epoch 49/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9927 - loss: 0.0313 - val_accuracy: 0.9951 - val_loss: 0.0300\n",
      "Epoch 50/50\n",
      "\u001b[1m96/96\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9937 - loss: 0.0307 - val_accuracy: 0.9951 - val_loss: 0.0291\n"
     ]
    }
   ],
   "source": [
    "#hyper-parameters for optimizer\n",
    "learning_rate = 0.001\n",
    "opt = optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model over 50 epochs using 10-observation batches and using the test holdout dataset for validation\n",
    "num_epochs = 50\n",
    "history = model.fit(x_train, y_train, epochs=num_epochs, batch_size=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the training process is running, let's try to understand what's happening:\n",
    "\n",
    "1. In each *epoch*, the full set of training data is passed forward through the network. There are four features for each observation, and four corresponding nodes in the input layer - so the features for each observation are passed as a vector of four values to that layer. However, for efficiency, the feature vectors are grouped into batches; so actually a matrix of multiple feature vectors is fed in each time.\n",
    "2. The matrix of feature values is processed by a function that performs a weighted sum using initialized weights and bias values. The result of this function is then processed by the activation function for the input layer to constrain the values passed to the nodes in the next layer.\n",
    "3. The weighted sum and activation functions are repeated in each layer. Note that the functions operate on vectors and matrices rather than individual scalar values. In other words, the forward pass is essentially a series of nested linear algebra functions. This is the reason data scientists prefer to use computers with graphical processing units (GPUs), since these are optimized for matrix and vector calculations.\n",
    "4. In the final layer of the network, the output vectors contain a probability value for each possible class (in this case, classes 0, 1, and 2). This vector is processed by a *loss function* to determine how far the values calculated by the network are from the actual values - so for example, suppose the output for a Gentoo penguin (class 1) observation is \\[0.3, 0.4, 0.3\\]. The correct prediction should be \\[0.0, 1.0, 0.0\\], so the variance between the predicted and actual values (how far away the each predicted value is from what it should be) is \\[0.3, 0.6, 0.3\\]. This variance is aggregated for each batch and maintained as a running aggregate to calculate the overall level of error (*loss*) incurred by the training data for the epoch. The accuracy (proportion of correct predictions based on the highest probability value in the output vector) for the training data is also calculated.\n",
    "5. At the end of each epoch, the validation data is passed through the network, and its loss and accuracy are also calculated. It's important to do this because it enables us to compare the performance of the model using data on which it was not trained, helping us determine if it will generalize well for new data or if it's *overfitted* to the training data.\n",
    "6. After all the data has been passed forward through the network, the output of the loss function for the *training* data (but <u>not</u> the *validation* data) is passed to the opimizer. The precise details of how the optimizer processes the loss vary depending on the specific optimization algorithm being used; but fundamentally you can think of the entire network, from the input layer to the loss function as being one big nested (*composite*) function. The optimizer applies some differential calculus to calculate *partial derivatives* for the function with respect to each weight and bias value that was used in the network. It's possible to do this efficiently for a nested function due to something called the *chain rule*, which enables you to determine the derivative of a composite function from the derivatives of its inner function and outer functions. You don't really need to worry about the details of the math here (the optimizer does it for you), but the end result is that the partial derivatives tell us about the slope (or *gradient*) of the loss function with respect to each weight and bias value - in other words, we can determine whether to increase or decrease the weight and bias values in order to decrease the loss.\n",
    "7. Having determined in which direction to adjust the weights and biases, the optimizer uses the *learning rate* to determine by how much to adjust them; and then works backwards through the network in a process called *backpropagation* to assign new values to the weights and biases in each layer.\n",
    "8. Now the next epoch repeats the whole training, validation, and backpropagation process starting with the revised weights and biases from the previous epoch - which hopefully will result in a lower level of loss.\n",
    "9. The process continues like this for 50 epochs.\n",
    "\n",
    "## Review training and validation loss\n",
    "\n",
    "After training is complete, we can examine the loss metrics we recorded while training and validating the model. We're really looking for two things:\n",
    "* The loss should reduce with each epoch, showing that the model is learning the right weights and biases to predict the correct labels.\n",
    "* The training loss and validation loss should follow a similar trend, showing that the model is not overfitting to the training data.\n",
    "\n",
    "Let's plot the loss metrics and see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "epoch_nums = range(1,num_epochs+1)\n",
    "training_loss = history.history[\"loss\"]\n",
    "validation_loss = history.history[\"val_loss\"]\n",
    "plt.plot(epoch_nums, training_loss)\n",
    "plt.plot(epoch_nums, validation_loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the learned weights and biases\n",
    "\n",
    "The trained model consists of the final weights and biases that were determined by the optimizer during training. Based on our network model we should expect the following values for each layer:\n",
    "* Layer 1: There are four input values going to ten output nodes, so there should be 4 x 10 weights and 10 bias values.\n",
    "* Layer 2: There are ten input values going to ten output nodes, so there should be 10 x 10 weights and 10 bias values.\n",
    "* Layer 3: There are ten input values going to three output nodes, so there should be 10 x 3 weights and 3 bias values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Weights:\n",
      " [[ 0.6393772   0.5773873  -0.03005859  0.36499214  0.45543143  0.30788237\n",
      "  -0.17155585 -0.25953653  0.11753446 -0.55923223]\n",
      " [-0.8738281  -0.06418859 -0.68564343 -0.40381673  0.37147     0.8561052\n",
      "   0.26682615  0.05571653 -0.34836772 -0.30133393]\n",
      " [-0.6397187  -0.03299478  0.02250021  0.4765962  -0.3523927  -0.2717417\n",
      "  -0.55834115 -0.2272119   0.07524085  0.03954405]\n",
      " [ 0.18652958  0.08508164  0.337396    0.508418    0.02148062  0.00643977\n",
      "  -0.05520463  0.5967475  -0.20046729 -0.14572966]] \n",
      "Biases:\n",
      " [-0.4037958  -0.10379446 -0.07222695  0.09146965 -0.20283395  0.15154433\n",
      "  0.          0.26706114  0.          0.        ]\n",
      "------------\n",
      "Weights:\n",
      " [[-0.19846582  0.10438661 -0.07179888 -0.5009155  -0.35263592  0.39509812\n",
      "  -0.2976881  -0.71975106  0.3852482   0.64116263]\n",
      " [-0.13685909  0.18892944  0.40613    -0.293172    0.45001143 -0.57887304\n",
      "   0.4427632  -0.46887675  0.16969617  0.41434598]\n",
      " [ 0.17977422  1.2624062  -0.69525534  0.06469971  0.06777295 -0.42032236\n",
      "   0.5334734   1.2725743   0.00621859  1.2412969 ]\n",
      " [ 0.18738705 -0.04446044  0.2505459  -0.0502454   0.11506138  0.46828705\n",
      "  -0.21647263  0.56618065 -0.23722172  0.27860248]\n",
      " [-0.41684765  0.21359517  0.18683282  0.4034375  -0.50239104 -0.22357394\n",
      "  -0.1386894   0.42500672 -0.23829465  0.08900912]\n",
      " [-0.14746955 -0.26370555  0.30311587 -0.42597663  0.16162263 -0.13451394\n",
      "  -0.43116406 -0.1438967  -0.14039455 -0.2969395 ]\n",
      " [-0.08779094 -0.5222384   0.13917077 -0.54189825  0.34636033  0.06773508\n",
      "   0.30837    -0.14798787 -0.24679655 -0.02274972]\n",
      " [-0.280925    0.10936909 -0.43304676  0.22488439  0.31475672 -0.48078576\n",
      "   0.3083307  -0.0267412   0.19113964 -0.38512957]\n",
      " [ 0.23076999  0.21088207  0.44993925  0.3925519  -0.36109096 -0.01786745\n",
      "   0.5177494  -0.39159977 -0.40818384 -0.48615342]\n",
      " [ 0.3603872  -0.0820947  -0.49093997 -0.18823785 -0.25604123 -0.14848736\n",
      "  -0.2359052  -0.06307912 -0.05701777  0.29893118]] \n",
      "Biases:\n",
      " [ 0.          0.13306308 -0.05885153  0.          0.25860676 -0.06959198\n",
      "  0.          0.2765237  -0.00921547 -0.3349686 ]\n",
      "------------\n",
      "Weights:\n",
      " [[ 0.41330934 -0.00405115  0.18406314]\n",
      " [ 0.15998262  0.56460047 -0.16600019]\n",
      " [ 0.12907347 -0.3844082   0.45567814]\n",
      " [-0.251248   -0.36212844 -0.0460071 ]\n",
      " [ 0.55721134  0.2528635  -0.652627  ]\n",
      " [ 0.6283683   0.23828971  0.62137353]\n",
      " [ 0.6545429   0.50029004  0.13169825]\n",
      " [ 0.15774454  0.0081729  -0.8332798 ]\n",
      " [ 0.6283793  -0.4988159  -0.06468978]\n",
      " [-0.250459    0.5011698   0.61811   ]] \n",
      "Biases:\n",
      " [ 0.22592463 -0.03472535 -0.23498076]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()[0]\n",
    "    biases = layer.get_weights()[1]\n",
    "    print('------------\\nWeights:\\n',weights,'\\nBiases:\\n', biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance\n",
    "\n",
    "So, is the model any good? The raw accuracy reported from the validation data would seem to indicate that it predicts pretty well; but it's typically useful to dig a little deeper and compare the predictions for each possible class. A common way to visualize the performance of a classification model is to create a *confusion matrix* that shows a crosstab of correct and incorrect predictions for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tensorflow doesn't have a built-in confusion matrix metric, so we'll use SciKit-Learn\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "class_probabilities = model.predict(x_test)\n",
    "predictions = np.argmax(class_probabilities, axis=1)\n",
    "true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(penguin_classes))\n",
    "plt.xticks(tick_marks, penguin_classes, rotation=85)\n",
    "plt.yticks(tick_marks, penguin_classes)\n",
    "plt.xlabel(\"Predicted Species\")\n",
    "plt.ylabel(\"Actual Species\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix should show a strong diagonal line indicating that there are more correct than incorrect predictions for each class.\n",
    "\n",
    "## Save the trained model\n",
    "Now that we have a model we believe is reasonably accurate, we can save its trained weights for use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved as models/penguin-classifier.h5\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "modelFileName = 'models/penguin-classifier.h5'\n",
    "model.save(modelFileName)\n",
    "del model  # deletes the existing model variable\n",
    "print('model saved as', modelFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the trained model\n",
    "\n",
    "When we have a new penguin observation, we can use the model to predict the species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample: [[50.4 15.3 20.  50. ]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Gentoo\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model = models.load_model(modelFileName)\n",
    "\n",
    "# CReate a new array of features\n",
    "x_new = np.array([[50.4,15.3,20,50]])\n",
    "print ('New sample: {}'.format(x_new))\n",
    "\n",
    "# Use the model to predict the class\n",
    "class_probabilities = model.predict(x_new)\n",
    "predictions = np.argmax(class_probabilities, axis=1)\n",
    "\n",
    "print(penguin_classes[predictions[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn more\n",
    "\n",
    "This notebook was designed to help you understand the basic concepts and principles involved in deep neural networks, using a simple Tensorflow example. To learn more about Tensorflow, take a look at the <a href=\"https://www.tensorflow.org/\" target=\"_blank\">Tensorflow web site</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
